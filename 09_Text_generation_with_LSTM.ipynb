{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "09-Text-generation-with-LSTM.ipynb",
      "provenance": [],
      "mount_file_id": "1ui3UKc8Iq80wkFXc61obC0ZRu-9wyb7Y",
      "authorship_tag": "ABX9TyNWyBc+r7WpS0bsByEvMLzo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/noircir/Python/blob/master/09_Text_generation_with_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IeUNhYLLzHsH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# CAREFUL ! THE model.fit() RUNS FOR ABOUT 2-3 HOURS ON CPU ! CHANGE TO GPU ! (3+ times faster)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hfyG4TnO8FwZ",
        "colab_type": "text"
      },
      "source": [
        "# Load text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPPreh2yNsRH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!pip install docx2txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v-3APuhzNveW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import docx2txt\n",
        "import re\n",
        "import string"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "miV5UACfOPyd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compress(text):\n",
        "  '''\n",
        "  removes blank lines and replaces multiple spaces with one space\n",
        "  '''\n",
        "  text = text.replace('\\t', ' ')\n",
        "  return re.sub('\\n+', '\\n', text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GISg0s3DORdU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text = docx2txt.process ('/content/drive/My Drive/Colab Notebooks/Self-learning chatbot/texts/document16.docx')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqNQWwEmOoYN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPeXlzjkS5Eo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text = text.replace(u'\\xa0', u' ')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Edt6_8ZTBk1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9J83Kit9bvG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text = compress(text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vAN2rbBm9khD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FWyR2lKMO0lX",
        "colab_type": "text"
      },
      "source": [
        "## Tokenize and Clean Text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NrzLwn1rNkmv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import spacy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-SnHbiqGO6Z_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!python -m spacy download fr_core_news_sm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXuXs1DMPJvI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# To load French vocab, RESTART THE RUNTIME !!\n",
        "\n",
        "nlp = spacy.load('fr_core_news_sm',disable=['parser', 'tagger','ner'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_dpHnyaPTNE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# (Needs further fine-tuning for multiple blank lines)\n",
        "\n",
        "def separate_punc(doc_text):\n",
        "    return [token.text.lower() for token in nlp(doc_text) \n",
        "    if token.text not in '\\n\\n \\n\\n\\n!\"-#$%&()--.*+,-/:;<=>?@[\\\\]^_`{|}~\\t\\n \\n\\n\\t\\t \\n\\n\\n\\n\\n \\n\\n\\n\\n \\n\\n\\n\\t']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6lnIpH8XQcEr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokens = separate_punc(text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0bJ5b-25QrSD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#tokens"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hb_atpi_Qsba",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "897dbe7d-eb48-4284-bbea-d1e9df406d60"
      },
      "source": [
        "len(tokens)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14485"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dLNvTTO7TZFb",
        "colab_type": "text"
      },
      "source": [
        "## Create Sequences of Tokens"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fXLYToH6TVy3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# organize into sequences of tokens. \n",
        "# A sequence of 20 words (for example), then predict the 21th word. \n",
        "\n",
        "train_len = 20+1 # training words , then one target word\n",
        "\n",
        "# Empty list of sequences\n",
        "text_sequences = []\n",
        "\n",
        "for i in range(train_len, len(tokens)):\n",
        "    \n",
        "    # Grab train_len# amount of characters\n",
        "    seq = tokens[i-train_len:i]\n",
        "    \n",
        "    # Add to list of sequences\n",
        "    text_sequences.append(seq)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zR8AW5NqTdbK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Given 20 words, can you predict the 21st (the last one) ?\n",
        "\n",
        "' '.join(text_sequences[100])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u90mkVrLTo4n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "' '.join(text_sequences[220])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTFvGoAZTsTk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "' '.join(text_sequences[400])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_fy192gTvVW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ca1c1569-f5e2-4f12-f1e7-7f81ac0b4e37"
      },
      "source": [
        "len(text_sequences)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14464"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-tASH05T3TK",
        "colab_type": "text"
      },
      "source": [
        "## Keras Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qN87zJFoTyEx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "765923d1-69fc-4a16-da8c-32c34f1d5011"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fLU0gzZpT6CR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Integer-encode sequences of words\n",
        "# Tokenizer() has many options, including punctiuation and the number of words to be kept...\n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(text_sequences)\n",
        "sequences = tokenizer.texts_to_sequences(text_sequences)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5IdddpoT9zu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "d5ff042d-e59b-4306-c653-b45df700db77"
      },
      "source": [
        "# Each of these numbers is an id for a particular word\n",
        "\n",
        "sequences[0]"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[48,\n",
              " 9,\n",
              " 45,\n",
              " 220,\n",
              " 175,\n",
              " 9,\n",
              " 48,\n",
              " 9,\n",
              " 45,\n",
              " 54,\n",
              " 11,\n",
              " 2003,\n",
              " 592,\n",
              " 591,\n",
              " 1,\n",
              " 469,\n",
              " 2001,\n",
              " 11,\n",
              " 142,\n",
              " 468,\n",
              " 34]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p1I74xfoUAjB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "975158b7-cf44-4ca0-b8ad-c2f1f6147529"
      },
      "source": [
        "tokenizer.index_word[50]"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'prix'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HG-5od3wUC5V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "5b583bad-0a0f-4da9-8f26-9bea40b48a82"
      },
      "source": [
        "for i in sequences[50]:\n",
        "    print(f'{i} : {tokenizer.index_word[i]}')"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "152 : documentation\n",
            "9 : d’\n",
            "1132 : appels\n",
            "9 : d’\n",
            "45 : offres\n",
            "142 : biens\n",
            "468 : informatiques\n",
            "34 : logiciel\n",
            "11 : contrat\n",
            "278 : version\n",
            "763 : détaillée\n",
            "764 : 2019\n",
            "173 : 12\n",
            "174 : 20\n",
            "1133 : table\n",
            "17 : des\n",
            "1134 : matières\n",
            "592 : page\n",
            "765 : préambule\n",
            "1135 : 9\n",
            "14 : \n",
            "  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LDbdDPdOVHQB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Word counts\n",
        "\n",
        "#tokenizer.word_counts"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6KVJnKQVL04",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "701a6591-132a-434c-d8a4-ae92ead55bb8"
      },
      "source": [
        "# Vocabulary size\n",
        "\n",
        "vocabulary_size = len(tokenizer.word_counts)\n",
        "vocabulary_size"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2004"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XUJeGoLLVTDi",
        "colab_type": "text"
      },
      "source": [
        "## Convert to Numpy Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GapWRIHFVPtH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-FTNyvbuVVry",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sequences = np.array(sequences)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6EaNMEplVYyl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "b11e3f0a-b27b-479c-a8d9-6bcad36f5b57"
      },
      "source": [
        "sequences"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  48,    9,   45, ...,  142,  468,   34],\n",
              "       [   9,   45,  220, ...,  468,   34,  278],\n",
              "       [  45,  220,  175, ...,   34,  278,  763],\n",
              "       ...,\n",
              "       [   7,  216,   17, ..., 1125, 1126, 1127],\n",
              "       [ 216,   17,  219, ..., 1126, 1127,   11],\n",
              "       [  17,  219,  162, ..., 1127,   11,   46]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YMCthr0NVeJz",
        "colab_type": "text"
      },
      "source": [
        "# Creating an LSTM-based model\n",
        "\n",
        "Predict the last word in a sequence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFabKhuBVbKd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,LSTM,Embedding # Embedding layer deals with vocabulary"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xaalrQWFVhL1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# PARAMETERS CHOICE\n",
        "\n",
        "# Activation = RELU\n",
        "# The size of the output layer is 'vocabulary_size'\n",
        "# Loss = 'categorical_crossentropy'\n",
        "\n",
        "def create_model(vocabulary_size, seq_len):\n",
        "    model = Sequential()\n",
        "    # Embedding turns positive integers(indexes) into dense vectors of fixed size (see docs).\n",
        "    model.add(Embedding(vocabulary_size, 20, input_length=seq_len)) \n",
        "    model.add(LSTM(150, return_sequences=True)) # better to take multiples of seq_len; smalle batches => faster\n",
        "    model.add(LSTM(150))\n",
        "    model.add(Dense(150, activation='relu'))\n",
        "\n",
        "    model.add(Dense(vocabulary_size, activation='softmax'))\n",
        "    \n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "   \n",
        "    model.summary()\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mdUDrScnVnzB",
        "colab_type": "text"
      },
      "source": [
        "## Feature / Label Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_lowGlOVjwu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.utils import to_categorical"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QX_MXYseVrZe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "0a9091e5-4302-4e58-f547-0676f914f70f"
      },
      "source": [
        "# First 20 words (compare to 'sequences' : it's everything without the last index)\n",
        "sequences[:,:-1]"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  48,    9,   45, ...,   11,  142,  468],\n",
              "       [   9,   45,  220, ...,  142,  468,   34],\n",
              "       [  45,  220,  175, ...,  468,   34,  278],\n",
              "       ...,\n",
              "       [   7,  216,   17, ...,  174, 1125, 1126],\n",
              "       [ 216,   17,  219, ..., 1125, 1126, 1127],\n",
              "       [  17,  219,  162, ..., 1126, 1127,   11]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5zUGxMdVuBz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a6b71b0b-f98d-441c-8f68-c4e90d554c45"
      },
      "source": [
        "# last word\n",
        "sequences[:,-1]"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  34,  278,  763, ..., 1127,   11,   46])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CnGk4S6_V09V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0e25b56c-c65f-48e4-86d6-6b58c0d94023"
      },
      "source": [
        "# X is the arrays of 20 words (sequences)\n",
        "\n",
        "X = sequences[:,:-1]\n",
        "\n",
        "# y (the target) is the 21st element\n",
        "y = sequences[:,-1]\n",
        "\n",
        "# one-hot\n",
        "y = to_categorical(y, num_classes=vocabulary_size+1)\n",
        "\n",
        "seq_len = X.shape[1]\n",
        "\n",
        "seq_len"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Qo09pXrWIEc",
        "colab_type": "text"
      },
      "source": [
        "## Training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CRytYaTQV3FS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "outputId": "989b26f7-d6c6-4611-8acf-1e302772a5c0"
      },
      "source": [
        "# define model\n",
        "model = create_model(vocabulary_size+1, seq_len) # +1 for Embeddings"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 20, 20)            40100     \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 20, 150)           102600    \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 150)               180600    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 150)               22650     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 2005)              302755    \n",
            "=================================================================\n",
            "Total params: 648,705\n",
            "Trainable params: 648,705\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Ksgn_DeWKH9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pickle import dump,load"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKxBR9NBWOBH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# fit model\n",
        "\n",
        "# CAREFUL ! IT RUNS FOR ABOUT 2 HOURS ON CPU ! CHANGE TO GPU !\n",
        "\n",
        "model.fit(X, y, batch_size=128, epochs=300,verbose=1). # epochs: at least > 200"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2_qqT-LMM0F3",
        "colab_type": "text"
      },
      "source": [
        "# Generating New Text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPO2UHJmWQUu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from random import randint\n",
        "from pickle import load\n",
        "from keras.models import load_model\n",
        "from keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lCgB11oILsMO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_text(model, tokenizer, seq_len, seed_text, num_gen_words):\n",
        "    '''\n",
        "    INPUTS:\n",
        "    model : model that was trained on text data\n",
        "    tokenizer : tokenizer that was fit on text data\n",
        "    seq_len : length of training sequence\n",
        "    seed_text : raw string text to serve as the seed\n",
        "    num_gen_words : number of words to be generated by model\n",
        "    '''\n",
        "    \n",
        "    # Final Output\n",
        "    output_text = []\n",
        "    \n",
        "    # Intial Seed Sequence\n",
        "    input_text = seed_text\n",
        "    \n",
        "    # Create num_gen_words\n",
        "    for i in range(num_gen_words):\n",
        "        \n",
        "        # Take the input text string and encode it to a sequence\n",
        "        encoded_text = tokenizer.texts_to_sequences([input_text])[0]\n",
        "        \n",
        "        # Pad sequences to our trained rate \n",
        "        pad_encoded = pad_sequences([encoded_text], maxlen=seq_len, truncating='pre')\n",
        "        \n",
        "        # Predict Class Probabilities for each word\n",
        "        pred_word_ind = model.predict_classes(pad_encoded, verbose=0)[0] # [0] returns index \n",
        "        \n",
        "        # Grab word\n",
        "        pred_word = tokenizer.index_word[pred_word_ind] \n",
        "        \n",
        "        # Update the sequence of input text (shifting one over with the new word)\n",
        "        input_text += ' ' + pred_word\n",
        "        \n",
        "        output_text.append(pred_word)\n",
        "        \n",
        "    # Make it look like a sentence.\n",
        "    return ' '.join(output_text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CuPLHRVOQKu_",
        "colab_type": "text"
      },
      "source": [
        "## Save the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jglac3p0QJTP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('LSTM_model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RDvohqQ6M2nA",
        "colab_type": "text"
      },
      "source": [
        "## Grab a random seed sequence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKnFY1JHLym1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "7353f7b5-45dd-4a62-e68d-6faa583b906f"
      },
      "source": [
        "text_sequences[500]"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['de',\n",
              " 'services',\n",
              " 'entrepreneur',\n",
              " '21',\n",
              " '\\n  ',\n",
              " '7.01',\n",
              " 'statut',\n",
              " 'importante',\n",
              " '22',\n",
              " '\\n  ',\n",
              " '7.02',\n",
              " 'capacité',\n",
              " 'importante',\n",
              " '22',\n",
              " '\\n  ',\n",
              " '7.03',\n",
              " 'divulgation',\n",
              " 'importante',\n",
              " '22',\n",
              " '\\n  ',\n",
              " '7.04']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2GRfTfQENCk1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "random.seed(101)\n",
        "random_pick = random.randint(0,len(text_sequences))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ZB-cEtYNGkZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "c8ae5c42-0a80-410a-df39-6193e9639796"
      },
      "source": [
        "random_seed_text = text_sequences[random_pick]\n",
        "random_seed_text"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['cadre',\n",
              " 'd’',\n",
              " 'un',\n",
              " 'contrat',\n",
              " 'antérieur',\n",
              " 'avec',\n",
              " 'un',\n",
              " 'organisme',\n",
              " 'public',\n",
              " 'du',\n",
              " 'québec',\n",
              " 'fait',\n",
              " 'l’',\n",
              " 'objet',\n",
              " 'd’',\n",
              " 'une',\n",
              " 'évaluation',\n",
              " 'de',\n",
              " 'rendement',\n",
              " 'insatisfaisant',\n",
              " 'de']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kz-uwW-8NuAL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9842a460-7f65-41f4-b776-d0eb43c1ea1a"
      },
      "source": [
        "seed_text = ' '.join(random_seed_text)\n",
        "seed_text"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cadre d’ un contrat antérieur avec un organisme public du québec fait l’ objet d’ une évaluation de rendement insatisfaisant de'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ByD07v2wNz-v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "07ea7ddd-97ae-4712-9815-6e5433268be1"
      },
      "source": [
        "## GENERATED NEW TEXT !!!\n",
        "\n",
        "generate_text(model,tokenizer,seq_len,seed_text=seed_text,num_gen_words=20)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'la part de cet organisme public ne pas faire l’ objet d’ une requête en faillite volontaire ou involontaire ou'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUNh3PrIQio5",
        "colab_type": "text"
      },
      "source": [
        "## Exploring generated sequence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nTnP70eEN6sY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "outputId": "8b595ca6-9ba1-4388-9816-9333ced4bf73"
      },
      "source": [
        "for i,word in enumerate(text.split()):\n",
        "    if word == 'organisme':\n",
        "        print(' '.join(text.split()[i-20:i+20]))\n",
        "        print('\\n')"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "redevable d’un montant exigible en vertu d’une loi fiscale ou alimentaire, l’ORGANISME PUBLIC, étant ou agissant pour le compte d’un organisme public tel que défini à l’article 31.1.4 de la Loi sur l’administration fiscale, peut, s’il en est requis par\n",
            "\n",
            "\n",
            "tel consentement doit notamment respecter les critères suivants : ne pas avoir, dans le cadre d’un contrat antérieur avec un organisme public du Québec, fait l’objet d’une évaluation de rendement insatisfaisant de la part de cet organisme public; ne pas\n",
            "\n",
            "\n",
            "contrat antérieur avec un organisme public du Québec, fait l’objet d’une évaluation de rendement insatisfaisant de la part de cet organisme public; ne pas faire l’objet d’une requête en faillite volontaire ou involontaire ou de toute autre procédure relative à\n",
            "\n",
            "\n",
            "dernier qui ne peut s’y opposer sans motif sérieux, ajouter, aux mêmes termes et conditions, d’autres établissements membres de son organisme parmi ceux indiqués à l’annexe A - Liste des Établissements Participants, dans la section «Établissements membres intéressés». SIGNATURE LES\n",
            "\n",
            "\n",
            "de la déclarante) ANNEXE 10.15 B - FICHE D'INFORMATION SUR LA DESTRUCTION DES DOCUMENTS CONTENANT DES RENSEIGNEMENTS PERSONNELS [Facultative] Tout organisme public ou toute entreprise privée qui recueillent, détiennent, utilisent ou communiquent des renseignements personnels doivent mettre en place des\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4BHaRXhLQ3rq",
        "colab_type": "text"
      },
      "source": [
        "## To reuse the model, load it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8LdDSORLOigs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import load_model\n",
        "model = load_model('LSTM_model.h5')\n",
        "tokenizer =load(open('LSTM_model', 'rb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VPJaHY9OqD1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "generate_text(model,tokenizer,seq_len,seed_text=seed_text,num_gen_words=20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRQr_m59Op8e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SzoJJ75TOp4e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}