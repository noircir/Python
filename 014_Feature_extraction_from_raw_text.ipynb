{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "014-Feature-extraction-from-raw-text.ipynb",
      "provenance": [],
      "mount_file_id": "1qKnpWOywaF6EspkUNq5pxHYWzZGL5sVA",
      "authorship_tag": "ABX9TyN4QAXoPJvPz59yZ2uW+i8Q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/noircir/Python/blob/master/014_Feature_extraction_from_raw_text.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hdUt0JUjfU8J",
        "colab_type": "text"
      },
      "source": [
        "## Steps to build an NLP system that can turn a body of text into a numerical array of *features*.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uhTNBdc9fYue",
        "colab_type": "text"
      },
      "source": [
        "# Building a Natural Language Processor From Scratch\n",
        "In this section we'll use basic Python to build a rudimentary NLP system. We'll build a *corpus of documents* (two small text files), create a *vocabulary* from all the words in both documents, and then demonstrate a *Bag of Words* technique to extract features from each document.<br>\n",
        "<div class=\"alert alert-info\" style=\"margin: 20px\">**For illustration only!**</div>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JuhA3d4JfVmC",
        "colab_type": "code",
        "outputId": "5891ecef-f4be-4712-d46e-ce226ad2564a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%%writefile 1.txt\n",
        "This is a story about cats\n",
        "our feline pets\n",
        "Cats are furry animals"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing 1.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-5qN-34hvlI",
        "colab_type": "code",
        "outputId": "75e18bd7-1c2c-485e-d56f-496ae6f5e827",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%%writefile 2.txt\n",
        "This story is about surfing\n",
        "Catching waves is fun\n",
        "Surfing is a popular water sport"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing 2.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YrD679ZQhyrv",
        "colab_type": "code",
        "outputId": "80a065a3-47e2-4656-ccaf-6b27efaf7eae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# Build a vocabulary out of the two documents.\n",
        "\n",
        "vocab = {}\n",
        "i = 1\n",
        "\n",
        "with open('1.txt') as f:\n",
        "    x = f.read().lower().split()\n",
        "\n",
        "for word in x:\n",
        "    if word in vocab:\n",
        "        continue\n",
        "    else:\n",
        "        vocab[word]=i\n",
        "        i+=1\n",
        "\n",
        "print(vocab)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'this': 1, 'is': 2, 'a': 3, 'story': 4, 'about': 5, 'cats': 6, 'our': 7, 'feline': 8, 'pets': 9, 'are': 10, 'furry': 11, 'animals': 12}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qkUnp3EQjE1E",
        "colab_type": "code",
        "outputId": "d292386f-f74a-4aa4-ec53-aadeb6cbb2cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "with open('2.txt') as f:\n",
        "    x = f.read().lower().split()\n",
        "\n",
        "for word in x:\n",
        "    if word in vocab:\n",
        "        continue\n",
        "    else:\n",
        "        vocab[word]=i\n",
        "        i+=1\n",
        "\n",
        "print(vocab)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'this': 1, 'is': 2, 'a': 3, 'story': 4, 'about': 5, 'cats': 6, 'our': 7, 'feline': 8, 'pets': 9, 'are': 10, 'furry': 11, 'animals': 12, 'surfing': 13, 'catching': 14, 'waves': 15, 'fun': 16, 'popular': 17, 'water': 18, 'sport': 19}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MpdifyL5jIRP",
        "colab_type": "code",
        "outputId": "fb159fb2-b5b0-47f2-d4d2-cf446d55e6cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "## Feature extraction\n",
        "\n",
        "# Create an empty vector with the length of the vocabulary\n",
        "one = ['1.txt']+[0]*len(vocab)\n",
        "one"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['1.txt', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ipcFnTVajWn2",
        "colab_type": "code",
        "outputId": "39d02fe0-eec5-44ff-b773-ae68cec5fc77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# map the frequencies of each word in 1.txt to our vector:\n",
        "with open('1.txt') as f:\n",
        "    x = f.read().lower().split()\n",
        "    \n",
        "for word in x:\n",
        "    one[vocab[word]]+=1\n",
        "    \n",
        "one"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['1.txt', 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WGPNJU3IjZJC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "two = ['2.txt']+[0]*len(vocab)\n",
        "\n",
        "with open('2.txt') as f:\n",
        "    x = f.read().lower().split()\n",
        "    \n",
        "for word in x:\n",
        "    two[vocab[word]]+=1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46KDDrphjf4R",
        "colab_type": "code",
        "outputId": "4ba667a2-7568-420a-e04c-5a72a781dd06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Compare the two vectors (tw bags of words):\n",
        "print(f'{one}\\n{two}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['1.txt', 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]\n",
            "['2.txt', 1, 3, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 2, 1, 1, 1, 1, 1, 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YKfaaMBZjgPy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Next steps: clean (remove stopwords and punctiation, lemmatize), \n",
        "# calculate tf-idf weights of words. \n",
        "# Then add tags with information about POS, dependencies, etc. =>\n",
        "# this adds more dimensions to our data and enables a deeper understanding \n",
        "# of the context of specific documents. => Vectors become high-dimensional sparse matrices."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MzSkffnMmIk8",
        "colab_type": "text"
      },
      "source": [
        "# Feature extraction from text with Scikit-Learn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WRnRGln4mIRK",
        "colab_type": "code",
        "outputId": "c43e8a7d-1d82-407f-aac2-3ce86ab1f99d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('/content/drive/My Drive/Colab Notebooks/NLP-Spacy/TextFiles/smsspamcollection.tsv', sep='\\t')\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>message</th>\n",
              "      <th>length</th>\n",
              "      <th>punct</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "      <td>111</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "      <td>29</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "      <td>155</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "      <td>49</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "      <td>61</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  label                                            message  length  punct\n",
              "0   ham  Go until jurong point, crazy.. Available only ...     111      9\n",
              "1   ham                      Ok lar... Joking wif u oni...      29      6\n",
              "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...     155      6\n",
              "3   ham  U dun say so early hor... U c already then say...      49      6\n",
              "4   ham  Nah I don't think he goes to usf, he lives aro...      61      2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0TbkK6tCmqE0",
        "colab_type": "code",
        "outputId": "723199d9-49b8-497c-b1d0-aa66c486f1f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "df.isnull().sum()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "label      0\n",
              "message    0\n",
              "length     0\n",
              "punct      0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6FEwSABOmyWk",
        "colab_type": "code",
        "outputId": "0df1386d-bec9-427c-aba6-6e5e0048a16e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "df['label'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ham     4825\n",
              "spam     747\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6sJDfQHYnGJ0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = df['message']  # this time we want to look at the text\n",
        "y = df['label']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FCFZYT5jm0qF",
        "colab_type": "code",
        "outputId": "e54e8983-7c2a-4dbc-faf0-b5dd496471ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Text preprocessing, tokenizing and the ability to filter out stopwords \n",
        "# are all included in CountVectorizer, which builds a dictionary of features \n",
        "# and transforms documents to feature vectors.\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "count_vect = CountVectorizer()\n",
        "\n",
        "X_train_counts = count_vect.fit_transform(X_train)\n",
        "X_train_counts.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3733, 7082)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPPVy2aXnv3P",
        "colab_type": "code",
        "outputId": "7c2d6142-47db-4afb-e963-260af1368a50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 884
        }
      },
      "source": [
        "print(X_train_counts)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  (0, 1736)\t1\n",
            "  (0, 4415)\t1\n",
            "  (0, 7069)\t1\n",
            "  (1, 849)\t1\n",
            "  (1, 878)\t1\n",
            "  (1, 935)\t1\n",
            "  (1, 938)\t1\n",
            "  (1, 957)\t1\n",
            "  (1, 1797)\t1\n",
            "  (1, 1835)\t1\n",
            "  (1, 2156)\t2\n",
            "  (1, 2472)\t1\n",
            "  (1, 2566)\t1\n",
            "  (1, 2677)\t1\n",
            "  (1, 3008)\t1\n",
            "  (1, 3116)\t1\n",
            "  (1, 3280)\t1\n",
            "  (1, 3416)\t1\n",
            "  (1, 3501)\t1\n",
            "  (1, 3726)\t1\n",
            "  (1, 4018)\t1\n",
            "  (1, 4270)\t1\n",
            "  (1, 4470)\t1\n",
            "  (1, 4489)\t1\n",
            "  (1, 4513)\t1\n",
            "  :\t:\n",
            "  (3728, 6913)\t1\n",
            "  (3728, 6928)\t1\n",
            "  (3728, 7048)\t1\n",
            "  (3729, 1454)\t1\n",
            "  (3729, 3674)\t1\n",
            "  (3729, 3794)\t1\n",
            "  (3729, 5795)\t1\n",
            "  (3730, 2743)\t1\n",
            "  (3730, 3085)\t1\n",
            "  (3730, 4902)\t1\n",
            "  (3730, 5141)\t1\n",
            "  (3730, 5799)\t1\n",
            "  (3730, 5800)\t1\n",
            "  (3731, 3505)\t1\n",
            "  (3731, 4429)\t1\n",
            "  (3731, 5520)\t1\n",
            "  (3731, 6345)\t1\n",
            "  (3732, 2090)\t1\n",
            "  (3732, 3073)\t1\n",
            "  (3732, 3416)\t1\n",
            "  (3732, 3532)\t1\n",
            "  (3732, 4285)\t1\n",
            "  (3732, 5423)\t1\n",
            "  (3732, 5763)\t1\n",
            "  (3732, 6119)\t1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZcyjxZFEnCmL",
        "colab_type": "code",
        "outputId": "b137889e-e9bc-4cf8-c6d9-a6cb4f4e5f23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Transform Counts to Frequencies with Tf-idf\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "tfidf_transformer = TfidfTransformer()\n",
        "\n",
        "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
        "X_train_tfidf.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3733, 7082)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OV8gmSyOnbJF",
        "colab_type": "code",
        "outputId": "b1f495c4-5148-43be-c3b8-1e66b27aaace",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 884
        }
      },
      "source": [
        "print(X_train_tfidf)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  (0, 7069)\t0.6019702680143677\n",
            "  (0, 4415)\t0.35852876712053044\n",
            "  (0, 1736)\t0.7135046738275388\n",
            "  (1, 7048)\t0.06220835924135395\n",
            "  (1, 6330)\t0.12175375951774331\n",
            "  (1, 6250)\t0.18699157878309497\n",
            "  (1, 6247)\t0.12959378252338027\n",
            "  (1, 6219)\t0.07434593703652681\n",
            "  (1, 5791)\t0.236698937005449\n",
            "  (1, 5512)\t0.15094660409003707\n",
            "  (1, 5468)\t0.236698937005449\n",
            "  (1, 5443)\t0.22545044092015623\n",
            "  (1, 5437)\t0.22545044092015623\n",
            "  (1, 5436)\t0.17424313877010147\n",
            "  (1, 5243)\t0.22545044092015623\n",
            "  (1, 4519)\t0.1982400748683877\n",
            "  (1, 4518)\t0.12552667891184655\n",
            "  (1, 4513)\t0.09521739789951615\n",
            "  (1, 4489)\t0.236698937005449\n",
            "  (1, 4470)\t0.0931011308331512\n",
            "  (1, 4270)\t0.08916256276356054\n",
            "  (1, 4018)\t0.08517903405827136\n",
            "  (1, 3726)\t0.20194453011537272\n",
            "  (1, 3501)\t0.2062210098516256\n",
            "  (1, 3416)\t0.08402534579064598\n",
            "  :\t:\n",
            "  (3728, 2090)\t0.220194057121089\n",
            "  (3728, 1440)\t0.19745041735266144\n",
            "  (3728, 1080)\t0.2074000350927176\n",
            "  (3729, 5795)\t0.5474874445685368\n",
            "  (3729, 3794)\t0.4832600441125685\n",
            "  (3729, 3674)\t0.5570538854722596\n",
            "  (3729, 1454)\t0.39548476138075156\n",
            "  (3730, 5800)\t0.44622014318070863\n",
            "  (3730, 5799)\t0.44622014318070863\n",
            "  (3730, 5141)\t0.4067637630886313\n",
            "  (3730, 4902)\t0.4335180259065145\n",
            "  (3730, 3085)\t0.3180686806987631\n",
            "  (3730, 2743)\t0.3836832603205654\n",
            "  (3731, 6345)\t0.4026376302519309\n",
            "  (3731, 5520)\t0.5381468378117085\n",
            "  (3731, 4429)\t0.49426560750382176\n",
            "  (3731, 3505)\t0.5513460155811831\n",
            "  (3732, 6119)\t0.4501915902498888\n",
            "  (3732, 5763)\t0.4346489898851782\n",
            "  (3732, 5423)\t0.3143037156433208\n",
            "  (3732, 4285)\t0.5025929271884622\n",
            "  (3732, 3532)\t0.23005833119164934\n",
            "  (3732, 3416)\t0.18731630919231396\n",
            "  (3732, 3073)\t0.27817044471293617\n",
            "  (3732, 2090)\t0.3027016349164578\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mh5Fpjuuntfx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Using TfidfVecttorizer, instead of CountVectorizer\n",
        "# Converts a collection of raw documents to a matrix of TF-IDF features.\n",
        "# Equivalent to CountVectorizer followed by TfidfTransformer.\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMI9rUb-ocgX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TfidfVec = TfidfVectorizer(stop_words='english')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J10Ul1T0pDdC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_tfidf = TfidfVec.fit_transform(X_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uIRwN4bspJjU",
        "colab_type": "code",
        "outputId": "e6dbca0d-f65e-4eda-ad3c-f29fd438d749",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 884
        }
      },
      "source": [
        "print(X_train_tfidf) # different weights"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  (0, 1682)\t0.7643175120589921\n",
            "  (0, 6810)\t0.6448400892934248\n",
            "  (1, 4363)\t0.23420934589848316\n",
            "  (1, 2394)\t0.25692782234957695\n",
            "  (1, 5262)\t0.20585833407164308\n",
            "  (1, 4336)\t0.2796462988006707\n",
            "  (1, 3382)\t0.24363836555217044\n",
            "  (1, 1743)\t0.18064935619933836\n",
            "  (1, 1781)\t0.1919988484140977\n",
            "  (1, 5070)\t0.2663568420032642\n",
            "  (1, 911)\t0.2796462988006707\n",
            "  (1, 6043)\t0.22091988910107668\n",
            "  (1, 6040)\t0.15310766532681155\n",
            "  (1, 5263)\t0.2663568420032642\n",
            "  (1, 908)\t0.2796462988006707\n",
            "  (1, 5294)\t0.2796462988006707\n",
            "  (1, 5598)\t0.2796462988006707\n",
            "  (1, 5269)\t0.2663568420032642\n",
            "  (1, 5334)\t0.1783348065873963\n",
            "  (2, 3840)\t0.5864912369683677\n",
            "  (2, 4789)\t0.5864912369683677\n",
            "  (2, 3501)\t0.5586197793836414\n",
            "  (3, 3173)\t0.47065622909137744\n",
            "  (3, 3299)\t0.5402157093551054\n",
            "  (3, 2247)\t0.51454337483273\n",
            "  :\t:\n",
            "  (3728, 2224)\t0.4675008243643285\n",
            "  (3728, 6660)\t0.4675008243643285\n",
            "  (3728, 6675)\t0.39154125318646427\n",
            "  (3728, 3021)\t0.26077899741932115\n",
            "  (3728, 2033)\t0.26818566261748344\n",
            "  (3728, 2830)\t0.22604236235844813\n",
            "  (3729, 3553)\t0.6065003168574706\n",
            "  (3729, 3671)\t0.5261562256770648\n",
            "  (3729, 5602)\t0.5960847186709732\n",
            "  (3730, 5606)\t0.4462201431807085\n",
            "  (3730, 5607)\t0.4462201431807085\n",
            "  (3730, 4732)\t0.43351802590651445\n",
            "  (3730, 2654)\t0.3836832603205653\n",
            "  (3730, 2985)\t0.31806868069876304\n",
            "  (3730, 4968)\t0.40676376308863127\n",
            "  (3731, 3386)\t0.5513460155811831\n",
            "  (3731, 5341)\t0.5381468378117085\n",
            "  (3731, 4279)\t0.49426560750382176\n",
            "  (3731, 6129)\t0.4026376302519309\n",
            "  (3732, 4145)\t0.5334870982560479\n",
            "  (3732, 5575)\t0.46136667634961737\n",
            "  (3732, 5922)\t0.47786467367382884\n",
            "  (3732, 5249)\t0.3336238298609678\n",
            "  (3732, 2033)\t0.32130857422191333\n",
            "  (3732, 3413)\t0.24419991786123843\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8D-EIFWrW9a",
        "colab_type": "code",
        "outputId": "51c7ac6d-0ab6-4a23-8e60-d09a6af2001e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(X_train_tfidf.shape) # after removing stopwords, fewer features"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3733, 6823)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0WUTgBoqpPzt",
        "colab_type": "code",
        "outputId": "89b1ff59-e3bc-468b-de61-c5f21cdf039a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "## Train a classifier\n",
        "\n",
        "# LinearSVC is similar to SVC, but handles sparse input better, \n",
        "# and scales well to large numbers of samples. \n",
        "# https://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html\n",
        "\n",
        "from sklearn.svm import LinearSVC\n",
        "clf = LinearSVC()\n",
        "clf.fit(X_train_tfidf,y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
              "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
              "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
              "          verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YsS5GKLKtEhJ",
        "colab_type": "text"
      },
      "source": [
        "# Build a pipeline\n",
        "\n",
        "Only our training set has been vectorized into a full vocabulary. In order to perform an analysis on our test set we'll have to submit it to the same procedures. Scikit-Learn offers a Pipeline class that behaves as a compound classifier.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l3eJ5e19pn31",
        "colab_type": "code",
        "outputId": "dea806b9-1d4f-4fe6-94c6-1559d553acc6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "# from sklearn.svm import LinearSVC\n",
        "\n",
        "text_clf = Pipeline([('tfidf', TfidfVectorizer()),\n",
        "                     ('clf', LinearSVC()),\n",
        "])\n",
        "\n",
        "# Feed the training data through the pipeline\n",
        "text_clf.fit(X_train, y_train)  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('tfidf',\n",
              "                 TfidfVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 encoding='utf-8', input='content',\n",
              "                                 lowercase=True, max_df=1.0, max_features=None,\n",
              "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
              "                                 preprocessor=None, smooth_idf=True,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 sublinear_tf=False,\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=None, use_idf=True,\n",
              "                                 vocabulary=None)),\n",
              "                ('clf',\n",
              "                 LinearSVC(C=1.0, class_weight=None, dual=True,\n",
              "                           fit_intercept=True, intercept_scaling=1,\n",
              "                           loss='squared_hinge', max_iter=1000,\n",
              "                           multi_class='ovr', penalty='l2', random_state=None,\n",
              "                           tol=0.0001, verbose=0))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rzJVEQE-tjmm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = text_clf.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3itn2nli9RHR",
        "colab_type": "code",
        "outputId": "c7d17ca8-d89b-4800-8206-829c3f84bfba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "X_test"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3245    Squeeeeeze!! This is christmas hug.. If u lik ...\n",
              "944     And also I've sorta blown him off a couple tim...\n",
              "1044    Mmm thats better now i got a roast down me! i...\n",
              "2484        Mm have some kanji dont eat anything heavy ok\n",
              "812     So there's a ring that comes with the guys cos...\n",
              "                              ...                        \n",
              "4944    Check mail.i have mailed varma and kept copy t...\n",
              "3313    I know you are serving. I mean what are you do...\n",
              "3652         Want to send me a virtual hug?... I need one\n",
              "14                    I HAVE A DATE ON SUNDAY WITH WILL!!\n",
              "4758    hey, looks like I was wrong and one of the kap...\n",
              "Name: message, Length: 1839, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0nGldQV9OfU",
        "colab_type": "code",
        "outputId": "d8bba551-ad4e-4b5f-c11e-e1ecaf215411",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "predictions"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['ham', 'ham', 'ham', ..., 'ham', 'ham', 'ham'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJqs9_N_t5GX",
        "colab_type": "code",
        "outputId": "92fcf131-c1cf-4837-cba4-5b4cab599953",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from sklearn import metrics\n",
        "print(metrics.confusion_matrix(y_test,predictions))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1586    7]\n",
            " [  12  234]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vtQVBlBYt75G",
        "colab_type": "code",
        "outputId": "533f36c7-908a-47bf-c74a-733d089ab75d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "# Print a classification report\n",
        "print(metrics.classification_report(y_test,predictions))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.99      1.00      0.99      1593\n",
            "        spam       0.97      0.95      0.96       246\n",
            "\n",
            "    accuracy                           0.99      1839\n",
            "   macro avg       0.98      0.97      0.98      1839\n",
            "weighted avg       0.99      0.99      0.99      1839\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_Dm6eEvt-ug",
        "colab_type": "code",
        "outputId": "234eb389-8cfb-45bc-97f9-d0e69cfb4761",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Print the overall accuracy\n",
        "print(metrics.accuracy_score(y_test,predictions))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.989668297988037\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "01SaVef4uCeo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Using the text of the messages, our model performed exceedingly well; \n",
        "# it correctly predicted spam 98.97% of the time!"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WI2qJ94b9HHi",
        "colab_type": "code",
        "outputId": "072ab06d-6815-4040-e0f7-aaa1d5358962",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "text_clf.predict(['''\n",
        "Amy, Pete and Tom getting out within hours of each other consolidates the field \n",
        "a ton around Bernie and Joe. Elizabeth just raised $29 million in February \n",
        "and isn’t going anywhere. The big question mark is Bloomberg and how he performs \n",
        "on Super Tuesday.\n",
        "'''])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['ham'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvtVbZa09xGP",
        "colab_type": "code",
        "outputId": "0d6c5667-8f94-475c-bf40-1df089a2519d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "text_clf.predict(['''\n",
        "Are you going to convince Bernard to adopt his UBI policy? No?\n",
        "'''])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['ham'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1ZEWn_a-GIq",
        "colab_type": "code",
        "outputId": "1d708ec9-27c5-4886-f182-84e6ac7d2328",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Should be 'spam' as it is a promoted ad.\n",
        "\n",
        "text_clf.predict(['''\n",
        "More than 90% of IT Professionals in IDC’s CloudView Survey indicated \n",
        "that they would evolve their digital transformation strategies to encompass \n",
        "multicloud postures this year.\n",
        "'''])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['ham'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "41RkR9sO-Tdv",
        "colab_type": "code",
        "outputId": "a1a2bb9e-7fc4-4af5-a98a-1c43b8c21662",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Should be 'spam'\n",
        "# This model has trained on labeling crud-er messages as spam.\n",
        "# Polite messages squeeze through, even though they ARE spam.\n",
        "\n",
        "text_clf.predict(['''\n",
        "Apply for the NEW Amex Business Edge™ Card and start earning 3x the points on eligible office \n",
        "supplies & electronics. T&Cs apply. \n",
        "'''])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['ham'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7b7ohVC-o3v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}