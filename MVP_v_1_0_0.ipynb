{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MVP-v.1.0.0.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1vvHEk3H48fZ1Vv3DWfRitrmm2HFoKQco",
      "authorship_tag": "ABX9TyOJTr8HbHKwviOL9mSqDfFu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/noircir/Python/blob/master/MVP_v_1_0_0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aXZPcvBt2UDP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!pip install nltk"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ObLwO-0T2zlZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!pip install docx2txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5VchMjCE3DE0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import docx2txt\n",
        "import random  # for choosing random greetings\n",
        "import string  # for removing punctuation\n",
        "import warnings\n",
        "\n",
        "import nltk\n",
        "import numpy as np # for argsort\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cK_VqLQP8g5y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a list to store user questions\n",
        "user_questions_storage = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RbDBYJGw7aV3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Ignore any warning messages\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZntB7ag_kks0",
        "colab_type": "code",
        "outputId": "eec07290-f47f-4767-80c3-d2ced9079aeb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "nltk.download('punkt', quiet=True) # needed for sentence tokenizer\n",
        "#nltk.download('wordnet', quiet=True)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lSm98UNAwHhA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "doc10 = docx2txt.process(\"/content/drive/My Drive/document10.docx\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vn5ABbuowRyX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(doc10[15900:17500])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g7XNI0xBkouk",
        "colab_type": "code",
        "outputId": "8bdd6e97-34af-4c66-ffce-0b8f5e717d4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "type(doc10)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "str"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Av6oMvC6Ifb",
        "colab_type": "text"
      },
      "source": [
        "## Create tokens of sentences (bag of sentences)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FkqOdUb_kvrE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Tokenization\n",
        "text = doc10\n",
        "sentence_tokens = nltk.sent_tokenize(text) # Tokenize sentences (not words). Convert the text into a list of sentences\n",
        "\n",
        "for sentence in sentence_tokens:\n",
        "  sentence.strip()\n",
        "\n",
        "#Print the list of sentences\n",
        "print(sentence_tokens)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tmQvEFBS_BT3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for sentence in sentence_tokens:\n",
        "  print(sentence)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_USAS3PBZ1BS",
        "colab_type": "code",
        "outputId": "536e94dd-7511-4418-e7e8-8c701cf5bc04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(len(sentence_tokens))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "270\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SEHFAEQrk0Ex",
        "colab_type": "code",
        "outputId": "1a94626d-3496-4362-9626-a993db50f58d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "#Create a dictionary (key:value) pair to remove punctuations\n",
        "# (our translation table)\n",
        "# The ord() function returns an integer representing the Unicode character.\n",
        "\n",
        "remove_punct_dict = dict(  ( ord(punct),None) for punct in string.punctuation)\n",
        "\n",
        "#Print the punctuations\n",
        "print(string.punctuation)\n",
        "\n",
        "#Print the dictionary\n",
        "print(remove_punct_dict)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n",
            "{33: None, 34: None, 35: None, 36: None, 37: None, 38: None, 39: None, 40: None, 41: None, 42: None, 43: None, 44: None, 45: None, 46: None, 47: None, 58: None, 59: None, 60: None, 61: None, 62: None, 63: None, 64: None, 91: None, 92: None, 93: None, 94: None, 95: None, 96: None, 123: None, 124: None, 125: None, 126: None}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6PYKFrqp6OpT",
        "colab_type": "text"
      },
      "source": [
        "## Create a function for tokenizing individual words, to be used when vectorizing sentences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nuR5z8bRlC9Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Create a function to return a list of lemmatized lower case words after removing punctuations\n",
        "\n",
        "def LemNormalize(text):\n",
        "  # The translate() method returns a string where each character is mapped \n",
        "  # to its corresponding character as per the translation table.\n",
        "  return nltk.word_tokenize(text.lower().translate(remove_punct_dict))   \n",
        "\n",
        "#Print the tokenized text\n",
        "print(LemNormalize(text))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eoUugyzX6x-4",
        "colab_type": "text"
      },
      "source": [
        "## Keyword matching for some static cases like greetings and goodbyes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bAEDmTSzlRBi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Keyword Matching\n",
        "\n",
        "#Greeting Inputs\n",
        "GREETING_INPUTS = [\"hi\", \"hello\", \"hola\", \"greetings\", \"wassup\", \"hey\", \"bonjour\", \"salut\", \"ca va\", \"ça va\"]\n",
        "\n",
        "GREETING_RESPONSES=[\"Bonjour\", \"Salut\", \"Hello\", \"Hi there\", \"How are you?\", \"Good to see you\"]\n",
        "\n",
        "#Function to return a random greeting response to a users greeting\n",
        "def greeting(sentence):\n",
        "  for word in sentence.split():\n",
        "    if word.lower() in GREETING_INPUTS:\n",
        "      return random.choice(GREETING_RESPONSES)\n",
        "\n",
        "#Goodbye Inputs\n",
        "GOODBYE_INPUTS = [\"bonne journée\", \"bonne soirée\", \"a demain\", \"goodbye\", \"bye\", \n",
        "                  \"au tantot\", \"à demain\", \"au revoir\", \"adieu\", \"à plus tard\",\n",
        "                  \"à bientôt\", \"à tout à l’heure\", \"à la prochaine\", \"ciao\", \"je m'en vais\",\n",
        "                  \"je me casse\", \"je me tire\"]\n",
        "\n",
        "#Goodbye responses back to the user\n",
        "GOODBYE_RESPONSES=[\"Bonne journée\", \"À la prochaine\", \"Àu revoir\"]\n",
        "\n",
        "def goodbye(sentence):\n",
        "  for word in sentence.split():\n",
        "    if word.lower() in GOODBYE_INPUTS:\n",
        "      return random.choice(GOODBYE_RESPONSES)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZRMWM5u5OJd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Take the user response (user question) and append to the bag of sentences\n",
        "\n",
        "#The users response / query\n",
        "user_response = 'Organisme public?'\n",
        "\n",
        "user_response = user_response.lower() \n",
        "user_questions_storage.append(user_response)\n",
        "\n",
        "###Print the users query/ response\n",
        "print(user_response)\n",
        "\n",
        "#Set the chatbot response to an empty string\n",
        "robo_response = ''\n",
        "\n",
        "#Append the users response to the sentence list (remove later??)\n",
        "sentence_tokens.append(user_response)\n",
        "\n",
        "###Print the sentence list after appending the users response\n",
        "print(sentence_tokens)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHvi923n9Cg-",
        "colab_type": "code",
        "outputId": "d062757d-607f-4f65-f607-8d02f4f83044",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(user_questions_storage)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['organisme public?']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IcNtLpEN7b3A",
        "colab_type": "text"
      },
      "source": [
        "## Create TF-IDF vector object from the bag of sentences, with normalized weights. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vWLdB-6tzmWu",
        "colab_type": "code",
        "outputId": "065d7366-c9ee-46a5-92c8-7c39b75980d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 884
        }
      },
      "source": [
        "#Create a TfidfVectorizer Object\n",
        "\n",
        "# French stopwords: need to be added, a special case\n",
        "TfidfVec = TfidfVectorizer(tokenizer = LemNormalize)\n",
        "\n",
        "#Convert the text to a matrix of TF-IDF features\n",
        "tfidf = TfidfVec.fit_transform(sentence_tokens)\n",
        "\n",
        "###Print the TFIDF features\n",
        "print(tfidf)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  (0, 306)\t0.10942496267722723\n",
            "  (0, 711)\t0.19319390252600377\n",
            "  (0, 301)\t0.10942496267722723\n",
            "  (0, 300)\t0.10942496267722723\n",
            "  (0, 1985)\t0.22879510263789526\n",
            "  (0, 657)\t0.10942496267722723\n",
            "  (0, 1984)\t0.22879510263789526\n",
            "  (0, 128)\t0.21884992535445447\n",
            "  (0, 795)\t0.20384211408216488\n",
            "  (0, 1960)\t0.21884992535445447\n",
            "  (0, 1487)\t0.20384211408216488\n",
            "  (0, 1748)\t0.059290795819495395\n",
            "  (0, 144)\t0.10192105704108244\n",
            "  (0, 647)\t0.02137110446423469\n",
            "  (0, 123)\t0.10192105704108244\n",
            "  (0, 1375)\t0.092467253987227\n",
            "  (0, 1082)\t0.10942496267722723\n",
            "  (0, 599)\t0.09239535052451901\n",
            "  (0, 1725)\t0.057543428750471144\n",
            "  (0, 710)\t0.07787534580084127\n",
            "  (0, 1296)\t0.2897908537890057\n",
            "  (0, 1348)\t0.448702146896915\n",
            "  (0, 2030)\t0.20807210062881334\n",
            "  (0, 636)\t0.3235242033568414\n",
            "  (0, 305)\t0.36706090846645295\n",
            "  :\t:\n",
            "  (269, 183)\t0.08156015515612322\n",
            "  (269, 828)\t0.05435529528813816\n",
            "  (269, 926)\t0.05139442404277303\n",
            "  (269, 939)\t0.06528997157098639\n",
            "  (269, 1934)\t0.06237848104321737\n",
            "  (269, 1380)\t0.09163570943886251\n",
            "  (269, 970)\t0.07729965290139455\n",
            "  (269, 1986)\t0.022034082159634438\n",
            "  (269, 730)\t0.047446196563864736\n",
            "  (269, 221)\t0.09491884821349104\n",
            "  (269, 864)\t0.07791881490519227\n",
            "  (269, 728)\t0.0456057880834099\n",
            "  (269, 952)\t0.06703430998146179\n",
            "  (269, 661)\t0.056434711637024924\n",
            "  (269, 1748)\t0.023723098281932368\n",
            "  (269, 647)\t0.1710177118019995\n",
            "  (269, 123)\t0.08156015515612322\n",
            "  (269, 1375)\t0.07399495061181513\n",
            "  (269, 599)\t0.04929160759813439\n",
            "  (269, 710)\t0.12463617373578031\n",
            "  (269, 1296)\t0.1545993058027891\n",
            "  (269, 2030)\t0.1110035113032371\n",
            "  (269, 636)\t0.08629778441141683\n",
            "  (270, 1541)\t0.69065765148085\n",
            "  (270, 1364)\t0.7231818640224302\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n54A_hfY5ylc",
        "colab_type": "code",
        "outputId": "324783fe-e646-4196-c1b7-5817453eefd5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 799
        }
      },
      "source": [
        "#Get the measure of similarity (similarity scores)\n",
        "vals = cosine_similarity(tfidf[-1], tfidf)\n",
        "\n",
        "#Print the similarity scores\n",
        "print(vals)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.         0.01996979 0.00993813 0.         0.08443015 0.07409871\n",
            "  0.04651613 0.04331781 0.09423061 0.03090617 0.         0.02739862\n",
            "  0.10907719 0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.1121769  0.09917817 0.09889806\n",
            "  0.08253652 0.         0.06716817 0.0616664  0.09780414 0.09103693\n",
            "  0.06612591 0.1172763  0.0444093  0.17660637 0.         0.\n",
            "  0.09210981 0.         0.15249812 0.         0.         0.11646899\n",
            "  0.12446766 0.11947804 0.09246739 0.         0.1388039  0.11971019\n",
            "  0.17190916 0.13161    0.12141219 0.         0.13634251 0.\n",
            "  0.13878638 0.12888056 0.         0.076261   0.         0.08459284\n",
            "  0.09551158 0.15317938 0.09830322 0.16221634 0.14875464 0.13682213\n",
            "  0.         0.         0.         0.         0.09713925 0.\n",
            "  0.         0.         0.         0.15956234 0.         0.06930801\n",
            "  0.17256651 0.         0.07010212 0.         0.         0.\n",
            "  0.         0.         0.17264617 0.         0.10999825 0.11278728\n",
            "  0.         0.07791131 0.10699555 0.11599568 0.15979926 0.10650019\n",
            "  0.16609748 0.1427907  0.13511854 0.20773945 0.         0.18398002\n",
            "  0.         0.         0.         0.         0.16656363 0.\n",
            "  0.16336844 0.         0.         0.         0.         0.\n",
            "  0.         0.         0.25510319 0.10534313 0.10541531 0.\n",
            "  0.         0.         0.         0.         0.07107293 0.10799499\n",
            "  0.09609157 0.10676401 0.         0.         0.         0.0683846\n",
            "  0.         0.         0.0683846  0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.03426373 0.03493673 0.10086947 0.15586772 0.18973725 0.11428997\n",
            "  0.         0.         0.10626882 0.07522776 0.1016886  0.\n",
            "  0.11402603 0.10363541 0.10901088 0.11355729 0.         0.1153862\n",
            "  0.11298451 0.         0.24261571 0.         0.16021643 0.\n",
            "  0.16021643 0.         0.         0.04388711 0.11491794 0.\n",
            "  0.         0.10763745 0.14798409 0.         0.17347958 0.0741809\n",
            "  0.         0.         0.         0.         0.         0.07784173\n",
            "  0.         0.         0.07286871 0.         0.         0.\n",
            "  0.06384056 0.         0.         0.         0.         0.09155135\n",
            "  0.         0.07324283 0.         0.         0.         0.\n",
            "  0.         0.         0.02997425 0.05113092 0.16478944 0.\n",
            "  0.         0.11263753 0.         0.         0.         0.\n",
            "  0.10199153 0.         0.         0.         0.09615118 0.\n",
            "  0.         0.         0.1100911  0.1042367  0.         0.09820835\n",
            "  0.19228351 0.14989528 0.         0.         0.         0.09208334\n",
            "  0.19228351 0.14989528 0.         0.         0.         0.03754967\n",
            "  0.09736145 0.         0.         0.         0.         0.\n",
            "  0.         0.10897719 0.         0.         0.24539736 0.\n",
            "  0.45500792 0.         0.         0.         0.08098912 0.\n",
            "  0.         0.06460152 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.07130712 0.\n",
            "  1.        ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HkbWQjvaKnKz",
        "colab_type": "code",
        "outputId": "a1afb3ee-dbb4-4d42-b30a-20cb2117578a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        }
      },
      "source": [
        "# Get the index of the most similar text/sentence to the users response\n",
        "# sort by ascending, the last probability will be = 1, because the last sentence is the appended user's question.\n",
        "# numpy.argsort returns the indices that would sort an array.\n",
        "\n",
        "print(vals.argsort())\n",
        "idx1 = vals.argsort()[0][-2]\n",
        "idx2 = vals.argsort()[0][-3]\n",
        "idx3 = vals.argsort()[0][-4]\n",
        "print(idx1)\n",
        "print(idx2)\n",
        "print(idx3)\n",
        "\n",
        "print(sentence_tokens[idx1])\n",
        "print(sentence_tokens[idx2])\n",
        "print(sentence_tokens[idx3]) "
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[  0 143 150 151 155 160 163 165 167 169 170 142 173 177 180 181 182 183\n",
            "  184 186 187 189 190 174 191 141 139 107 109 110 111 112 113 114 115 119\n",
            "  120 140 121 123 128 129 130 132 133 269 136 137 138 122 193 194 195 241\n",
            "  242 243 244 245 246 248 249 251 253 238 254 257 258 260 261 262 263 264\n",
            "  265 266 267 255 237 236 232 196 198 200 201 202 203 204 205 209 210 212\n",
            "  213 214 215 217 218 219 221 222 223 226 230 231 105 104 135 102  74  73\n",
            "   72  71  69  68  67  66  58 103  53  51  45  40  39  37  35  34  25  20\n",
            "   19  18  17  16  15  14  13  10   3  76  79  56  81  82 100  87  83  90\n",
            "   85  84   2   1  11 206   9 144 145 239   7 171  32   6 207  27 192 259\n",
            "   30  26 131 134  77  80 124 268 188 199   5 179 153  57 185  91 256  24\n",
            "    4  59  29 197 233  36  44   8  60 126 220  70 240  28 227  62  23  22\n",
            "  146 154 216 157 225 117 118 152  95 127  92 175 125 247 158  12  88 224\n",
            "   21 211  89 162 159 156 149 172 161  93  41  31  43  47  50  42  55  49\n",
            "   98  52  65  54  46  97 176  64 229 235  38  61 147  75  94 166 168  63\n",
            "  108 208  96 106  48  78  86 178  33 101 148 234 228  99 164 250 116 252\n",
            "  270]]\n",
            "252\n",
            "116\n",
            "250\n",
            "(identifier l’organisme public).\n",
            "Embauche [Importante]\n",
            "\n",
            "\n",
            "\n",
            "Le PRESTATAIRE DE SERVICES s’engage à ne pas embaucher ou retenir les services d’un employé de l’ORGANISME PUBLIC ou ayant été à l’emploi de l’ORGANISME PUBLIC, aux fins de l’assigner directement ou indirectement à l’exécution du présent Contrat, à moins d’avoir obtenu l’autorisation préalable de l’ORGANISME PUBLIC.\n",
            "(identifier l’organisme public) ou par l’un de ses représentants autorisés.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ew6M7jaeMMgx",
        "colab_type": "code",
        "outputId": "dd435db7-813b-404c-b2e8-8813434e91cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 799
        }
      },
      "source": [
        "#Reduce the dimensionality of vals: flatten the matrix\n",
        "flat = vals.flatten()\n",
        "print(flat)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.         0.01996979 0.00993813 0.         0.08443015 0.07409871\n",
            " 0.04651613 0.04331781 0.09423061 0.03090617 0.         0.02739862\n",
            " 0.10907719 0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.1121769  0.09917817 0.09889806\n",
            " 0.08253652 0.         0.06716817 0.0616664  0.09780414 0.09103693\n",
            " 0.06612591 0.1172763  0.0444093  0.17660637 0.         0.\n",
            " 0.09210981 0.         0.15249812 0.         0.         0.11646899\n",
            " 0.12446766 0.11947804 0.09246739 0.         0.1388039  0.11971019\n",
            " 0.17190916 0.13161    0.12141219 0.         0.13634251 0.\n",
            " 0.13878638 0.12888056 0.         0.076261   0.         0.08459284\n",
            " 0.09551158 0.15317938 0.09830322 0.16221634 0.14875464 0.13682213\n",
            " 0.         0.         0.         0.         0.09713925 0.\n",
            " 0.         0.         0.         0.15956234 0.         0.06930801\n",
            " 0.17256651 0.         0.07010212 0.         0.         0.\n",
            " 0.         0.         0.17264617 0.         0.10999825 0.11278728\n",
            " 0.         0.07791131 0.10699555 0.11599568 0.15979926 0.10650019\n",
            " 0.16609748 0.1427907  0.13511854 0.20773945 0.         0.18398002\n",
            " 0.         0.         0.         0.         0.16656363 0.\n",
            " 0.16336844 0.         0.         0.         0.         0.\n",
            " 0.         0.         0.25510319 0.10534313 0.10541531 0.\n",
            " 0.         0.         0.         0.         0.07107293 0.10799499\n",
            " 0.09609157 0.10676401 0.         0.         0.         0.0683846\n",
            " 0.         0.         0.0683846  0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.03426373 0.03493673 0.10086947 0.15586772 0.18973725 0.11428997\n",
            " 0.         0.         0.10626882 0.07522776 0.1016886  0.\n",
            " 0.11402603 0.10363541 0.10901088 0.11355729 0.         0.1153862\n",
            " 0.11298451 0.         0.24261571 0.         0.16021643 0.\n",
            " 0.16021643 0.         0.         0.04388711 0.11491794 0.\n",
            " 0.         0.10763745 0.14798409 0.         0.17347958 0.0741809\n",
            " 0.         0.         0.         0.         0.         0.07784173\n",
            " 0.         0.         0.07286871 0.         0.         0.\n",
            " 0.06384056 0.         0.         0.         0.         0.09155135\n",
            " 0.         0.07324283 0.         0.         0.         0.\n",
            " 0.         0.         0.02997425 0.05113092 0.16478944 0.\n",
            " 0.         0.11263753 0.         0.         0.         0.\n",
            " 0.10199153 0.         0.         0.         0.09615118 0.\n",
            " 0.         0.         0.1100911  0.1042367  0.         0.09820835\n",
            " 0.19228351 0.14989528 0.         0.         0.         0.09208334\n",
            " 0.19228351 0.14989528 0.         0.         0.         0.03754967\n",
            " 0.09736145 0.         0.         0.         0.         0.\n",
            " 0.         0.10897719 0.         0.         0.24539736 0.\n",
            " 0.45500792 0.         0.         0.         0.08098912 0.\n",
            " 0.         0.06460152 0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.07130712 0.\n",
            " 1.        ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KO9qZcolNAQ9",
        "colab_type": "code",
        "outputId": "8d57d910-e269-45c5-f821-581d0d6e58d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 799
        }
      },
      "source": [
        "#sort the list in ascending order\n",
        "flat.sort()\n",
        "print(flat)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.00993813 0.01996979 0.02739862 0.02997425\n",
            " 0.03090617 0.03426373 0.03493673 0.03754967 0.04331781 0.04388711\n",
            " 0.0444093  0.04651613 0.05113092 0.0616664  0.06384056 0.06460152\n",
            " 0.06612591 0.06716817 0.0683846  0.0683846  0.06930801 0.07010212\n",
            " 0.07107293 0.07130712 0.07286871 0.07324283 0.07409871 0.0741809\n",
            " 0.07522776 0.076261   0.07784173 0.07791131 0.08098912 0.08253652\n",
            " 0.08443015 0.08459284 0.09103693 0.09155135 0.09208334 0.09210981\n",
            " 0.09246739 0.09423061 0.09551158 0.09609157 0.09615118 0.09713925\n",
            " 0.09736145 0.09780414 0.09820835 0.09830322 0.09889806 0.09917817\n",
            " 0.10086947 0.1016886  0.10199153 0.10363541 0.1042367  0.10534313\n",
            " 0.10541531 0.10626882 0.10650019 0.10676401 0.10699555 0.10763745\n",
            " 0.10799499 0.10897719 0.10901088 0.10907719 0.10999825 0.1100911\n",
            " 0.1121769  0.11263753 0.11278728 0.11298451 0.11355729 0.11402603\n",
            " 0.11428997 0.11491794 0.1153862  0.11599568 0.11646899 0.1172763\n",
            " 0.11947804 0.11971019 0.12141219 0.12446766 0.12888056 0.13161\n",
            " 0.13511854 0.13634251 0.13682213 0.13878638 0.1388039  0.1427907\n",
            " 0.14798409 0.14875464 0.14989528 0.14989528 0.15249812 0.15317938\n",
            " 0.15586772 0.15956234 0.15979926 0.16021643 0.16021643 0.16221634\n",
            " 0.16336844 0.16478944 0.16609748 0.16656363 0.17190916 0.17256651\n",
            " 0.17264617 0.17347958 0.17660637 0.18398002 0.18973725 0.19228351\n",
            " 0.19228351 0.20773945 0.24261571 0.24539736 0.25510319 0.45500792\n",
            " 1.        ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Hnp2gESNIp4",
        "colab_type": "code",
        "outputId": "ae989c82-1cca-4e39-dbd2-049af8006f97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "score1 = 0\n",
        "\n",
        "#Get three most similar scores to the users response\n",
        "score1 = flat[-2]\n",
        "score2 = flat[-3]\n",
        "score3 = flat[-4]\n",
        "\n",
        "#Print the similarity score\n",
        "print(score1)\n",
        "print(score2)\n",
        "print(score3)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.4550079202576168\n",
            "0.25510318524898845\n",
            "0.24539736108080817\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yex9lHlKNPbj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#If the variable 'score' is 0 then there is no text similar to the users response\n",
        "if(score1 == 0):\n",
        "  robo_response = robo_response + \"I apologize, I don't understand.\"\n",
        "else:\n",
        "  robo_response = robo_response + sentence_tokens[idx1]\n",
        "  \n",
        "#Print the chat bot response\n",
        "print(robo_response)\n",
        "  \n",
        "#Remove the users response from the sentence tokens list\n",
        "sentence_tokens.remove(user_response)\n",
        "#print(sentence_tokens)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0DMrQuZc-hAJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(sentence_tokens[-2:-1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AEgC1K2H-szt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(sentence_tokens[-3:-2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KT4hnRgI-xfF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(sentence_tokens[-4:-3])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ESX7uiga6mrB",
        "colab_type": "text"
      },
      "source": [
        "## Wrapped into a function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7CmtJqHlzjI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Generate the response\n",
        "def response(user_response):\n",
        "\n",
        "  user_response = user_response.lower() #Make the response lower case\n",
        "  user_questions_storage.append(user_response)\n",
        "\n",
        "  #Set the chatbot response to an empty string\n",
        "  robo_response = ''\n",
        "\n",
        "  #Append the users response to the sentence list\n",
        "  sentence_tokens.append(user_response)\n",
        "\n",
        "  ###Print the sentence list after appending the users response\n",
        "  #print(sent_tokens)\n",
        "\n",
        "  #Create a TfidfVectorizer Object\n",
        "  TfidfVec = TfidfVectorizer(tokenizer = LemNormalize, stop_words='english')\n",
        "\n",
        "  #Convert the text to a matrix of TF-IDF features\n",
        "  tfidf = TfidfVec.fit_transform(sentence_tokens)\n",
        "\n",
        "  ###Print the TFIDF features\n",
        "  #print(tfidf)\n",
        "\n",
        "  #Get the measure of similarity (similarity scores)\n",
        "  vals = cosine_similarity(tfidf[-1], tfidf)\n",
        "\n",
        "  #Print the similarity scores\n",
        "  #print(vals)\n",
        "\n",
        "  #Get the index of the most similar text/sentence to the users response\n",
        "  idx = vals.argsort()[0][-2]\n",
        "\n",
        "  #Reduce the dimensionality of vals\n",
        "  flat = vals.flatten()\n",
        "\n",
        "  #sort the list in ascending order\n",
        "  flat.sort()\n",
        "\n",
        "  #Get the most similar score to the users response\n",
        "  score = flat[-2]\n",
        "\n",
        "  #Print the similarity score\n",
        "  #print(score)\n",
        "\n",
        "  #If the variable 'score' is 0 then their is no text similar to the users response\n",
        "  if(score == 0):\n",
        "    robo_response = robo_response+\"I apologize, I don't understand.\"\n",
        "  else:\n",
        "    robo_response = robo_response+sentence_tokens[idx]\n",
        "  \n",
        "  #Print the chat bot response\n",
        "  #print(robo_response)\n",
        "  \n",
        "  #Remove the users response from the sentence tokens list\n",
        "  sentence_tokens.remove(user_response)\n",
        "  \n",
        "  return robo_response"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFrkHlCim8VK",
        "colab_type": "code",
        "outputId": "4b4a0b8b-4df5-46dc-e35f-28347e4ac56c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 836
        }
      },
      "source": [
        "flag = True\n",
        "print(\"CONTRAT_Bot: I am here to help you create a tender contract. If you want to exit, type Bye!\")\n",
        "while(flag == True):\n",
        "  user_response = input()\n",
        "  user_response = user_response.lower()\n",
        "  if(user_response != 'bye'):\n",
        "    if(user_response == 'thanks' or user_response =='thank you'):\n",
        "      flag=False\n",
        "      print(\"CONTRAT_Bot: You are welcome !\")\n",
        "    else:\n",
        "      if(greeting(user_response) != None):\n",
        "        print(\"CONTRAT_Bot: \" + greeting(user_response))\n",
        "      else:\n",
        "        print(\"CONTRAT_Bot: \" + response(user_response))       \n",
        "  else:\n",
        "    flag = False\n",
        "    print(\"CONTRAT_Bot: Chat with you later !\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CONTRAT_Bot: I am here to help you create a tender contract. If you want to exit, type Bye!\n",
            "bonjour\n",
            "CONTRAT_Bot: How are you?\n",
            "frais\n",
            "CONTRAT_Bot: Frais\n",
            "\n",
            "\n",
            "\n",
            "Les frais de l’arbitrage y compris les honoraires et les débours des PARTIES sont attribués par l’arbitre de la manière qu’il juge à propos dans les circonstances.\n",
            "clause de frais\n",
            "CONTRAT_Bot: Frais\n",
            "\n",
            "\n",
            "\n",
            "Les frais de l’arbitrage y compris les honoraires et les débours des PARTIES sont attribués par l’arbitre de la manière qu’il juge à propos dans les circonstances.\n",
            "responsabilite\n",
            "CONTRAT_Bot: I apologize, I don't understand.\n",
            "responsabilité\n",
            "CONTRAT_Bot: Étendue de la responsabilité\n",
            "\n",
            "\n",
            "\n",
            "Nonobstant ce qui précède, cette section ne limite pas la responsabilité du PRESTATAIRE DE SERVICES au Contrat.\n",
            "SÛRETÉS\n",
            "CONTRAT_Bot: SÛRETÉS\n",
            "\n",
            "\n",
            "\n",
            "(Négative)\n",
            "\n",
            "L’ORGANISME PUBLIC confirme qu’aucune garantie d’exécution n’est requise par les présentes.\n",
            "suretes\n",
            "CONTRAT_Bot: I apologize, I don't understand.\n",
            "garantie\n",
            "CONTRAT_Bot: OU\n",
            "\n",
            "\n",
            "\n",
            "(Affirmative - Pourcentage - Sans cautionnement - Avec effet de commerce)\n",
            "\n",
            "Constitution\n",
            "\n",
            "\n",
            "\n",
            "Le PRESTATAIRE DE SERVICES doit, dans les Délai de transmission de la garantie d'exécution jours à compter de la date de l’envoi de l’avis d’adjudication, fournir à l’ORGANISME PUBLIC une garantie d’exécution, soit un chèque certifié, un mandat-poste ou une traite bancaire, d’un montant équivalant à Pourcentage du montant du Contrat pour la garantie d'exécution du montant du Contrat.\n",
            "bye\n",
            "CONTRAT_Bot: Chat with you later !\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7pT4BW7FnLVr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}