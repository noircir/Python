{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "name": "020-Keras-Basics.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/noircir/Python/blob/master/020_Keras_Basics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VdsrKtaELBNY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hYB5I7xlLBNf",
        "colab_type": "text"
      },
      "source": [
        "## Dataset\n",
        "\n",
        "We will use the famous Iris Data set.\n",
        "_____\n",
        "More info on the data set:\n",
        "https://en.wikipedia.org/wiki/Iris_flower_data_set\n",
        "\n",
        "## Reading in the Data Set\n",
        "\n",
        "We've already downloaded the dataset, its in this folder. So let's open it up. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-lqanbs_LBNi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.datasets import load_iris"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gW0VfX_PLBNp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "iris = load_iris()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GaHpOPc9LBNu",
        "colab_type": "code",
        "outputId": "ea27cd94-32db-4a10-8d9e-213c7a55835f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "type(iris)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "sklearn.utils.Bunch"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSjx1kE5LBN1",
        "colab_type": "code",
        "outputId": "20e19568-c531-4674-806e-e3223ddf7786",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "print(iris.DESCR)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".. _iris_dataset:\n",
            "\n",
            "Iris plants dataset\n",
            "--------------------\n",
            "\n",
            "**Data Set Characteristics:**\n",
            "\n",
            "    :Number of Instances: 150 (50 in each of three classes)\n",
            "    :Number of Attributes: 4 numeric, predictive attributes and the class\n",
            "    :Attribute Information:\n",
            "        - sepal length in cm\n",
            "        - sepal width in cm\n",
            "        - petal length in cm\n",
            "        - petal width in cm\n",
            "        - class:\n",
            "                - Iris-Setosa\n",
            "                - Iris-Versicolour\n",
            "                - Iris-Virginica\n",
            "                \n",
            "    :Summary Statistics:\n",
            "\n",
            "    ============== ==== ==== ======= ===== ====================\n",
            "                    Min  Max   Mean    SD   Class Correlation\n",
            "    ============== ==== ==== ======= ===== ====================\n",
            "    sepal length:   4.3  7.9   5.84   0.83    0.7826\n",
            "    sepal width:    2.0  4.4   3.05   0.43   -0.4194\n",
            "    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n",
            "    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\n",
            "    ============== ==== ==== ======= ===== ====================\n",
            "\n",
            "    :Missing Attribute Values: None\n",
            "    :Class Distribution: 33.3% for each of 3 classes.\n",
            "    :Creator: R.A. Fisher\n",
            "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
            "    :Date: July, 1988\n",
            "\n",
            "The famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\n",
            "from Fisher's paper. Note that it's the same as in R, but not as in the UCI\n",
            "Machine Learning Repository, which has two wrong data points.\n",
            "\n",
            "This is perhaps the best known database to be found in the\n",
            "pattern recognition literature.  Fisher's paper is a classic in the field and\n",
            "is referenced frequently to this day.  (See Duda & Hart, for example.)  The\n",
            "data set contains 3 classes of 50 instances each, where each class refers to a\n",
            "type of iris plant.  One class is linearly separable from the other 2; the\n",
            "latter are NOT linearly separable from each other.\n",
            "\n",
            ".. topic:: References\n",
            "\n",
            "   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\n",
            "     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\n",
            "     Mathematical Statistics\" (John Wiley, NY, 1950).\n",
            "   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\n",
            "     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\n",
            "   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\n",
            "     Structure and Classification Rule for Recognition in Partially Exposed\n",
            "     Environments\".  IEEE Transactions on Pattern Analysis and Machine\n",
            "     Intelligence, Vol. PAMI-2, No. 1, 67-71.\n",
            "   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\n",
            "     on Information Theory, May 1972, 431-433.\n",
            "   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\n",
            "     conceptual clustering system finds 3 classes in the data.\n",
            "   - Many, many more ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQ7ToGamLBN6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = iris.data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5xeW2U3LBN_",
        "colab_type": "code",
        "outputId": "14444234-aeec-48c5-aa66-4d646b449dc4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "X"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[5.1, 3.5, 1.4, 0.2],\n",
              "       [4.9, 3. , 1.4, 0.2],\n",
              "       [4.7, 3.2, 1.3, 0.2],\n",
              "       [4.6, 3.1, 1.5, 0.2],\n",
              "       [5. , 3.6, 1.4, 0.2],\n",
              "       [5.4, 3.9, 1.7, 0.4],\n",
              "       [4.6, 3.4, 1.4, 0.3],\n",
              "       [5. , 3.4, 1.5, 0.2],\n",
              "       [4.4, 2.9, 1.4, 0.2],\n",
              "       [4.9, 3.1, 1.5, 0.1],\n",
              "       [5.4, 3.7, 1.5, 0.2],\n",
              "       [4.8, 3.4, 1.6, 0.2],\n",
              "       [4.8, 3. , 1.4, 0.1],\n",
              "       [4.3, 3. , 1.1, 0.1],\n",
              "       [5.8, 4. , 1.2, 0.2],\n",
              "       [5.7, 4.4, 1.5, 0.4],\n",
              "       [5.4, 3.9, 1.3, 0.4],\n",
              "       [5.1, 3.5, 1.4, 0.3],\n",
              "       [5.7, 3.8, 1.7, 0.3],\n",
              "       [5.1, 3.8, 1.5, 0.3],\n",
              "       [5.4, 3.4, 1.7, 0.2],\n",
              "       [5.1, 3.7, 1.5, 0.4],\n",
              "       [4.6, 3.6, 1. , 0.2],\n",
              "       [5.1, 3.3, 1.7, 0.5],\n",
              "       [4.8, 3.4, 1.9, 0.2],\n",
              "       [5. , 3. , 1.6, 0.2],\n",
              "       [5. , 3.4, 1.6, 0.4],\n",
              "       [5.2, 3.5, 1.5, 0.2],\n",
              "       [5.2, 3.4, 1.4, 0.2],\n",
              "       [4.7, 3.2, 1.6, 0.2],\n",
              "       [4.8, 3.1, 1.6, 0.2],\n",
              "       [5.4, 3.4, 1.5, 0.4],\n",
              "       [5.2, 4.1, 1.5, 0.1],\n",
              "       [5.5, 4.2, 1.4, 0.2],\n",
              "       [4.9, 3.1, 1.5, 0.2],\n",
              "       [5. , 3.2, 1.2, 0.2],\n",
              "       [5.5, 3.5, 1.3, 0.2],\n",
              "       [4.9, 3.6, 1.4, 0.1],\n",
              "       [4.4, 3. , 1.3, 0.2],\n",
              "       [5.1, 3.4, 1.5, 0.2],\n",
              "       [5. , 3.5, 1.3, 0.3],\n",
              "       [4.5, 2.3, 1.3, 0.3],\n",
              "       [4.4, 3.2, 1.3, 0.2],\n",
              "       [5. , 3.5, 1.6, 0.6],\n",
              "       [5.1, 3.8, 1.9, 0.4],\n",
              "       [4.8, 3. , 1.4, 0.3],\n",
              "       [5.1, 3.8, 1.6, 0.2],\n",
              "       [4.6, 3.2, 1.4, 0.2],\n",
              "       [5.3, 3.7, 1.5, 0.2],\n",
              "       [5. , 3.3, 1.4, 0.2],\n",
              "       [7. , 3.2, 4.7, 1.4],\n",
              "       [6.4, 3.2, 4.5, 1.5],\n",
              "       [6.9, 3.1, 4.9, 1.5],\n",
              "       [5.5, 2.3, 4. , 1.3],\n",
              "       [6.5, 2.8, 4.6, 1.5],\n",
              "       [5.7, 2.8, 4.5, 1.3],\n",
              "       [6.3, 3.3, 4.7, 1.6],\n",
              "       [4.9, 2.4, 3.3, 1. ],\n",
              "       [6.6, 2.9, 4.6, 1.3],\n",
              "       [5.2, 2.7, 3.9, 1.4],\n",
              "       [5. , 2. , 3.5, 1. ],\n",
              "       [5.9, 3. , 4.2, 1.5],\n",
              "       [6. , 2.2, 4. , 1. ],\n",
              "       [6.1, 2.9, 4.7, 1.4],\n",
              "       [5.6, 2.9, 3.6, 1.3],\n",
              "       [6.7, 3.1, 4.4, 1.4],\n",
              "       [5.6, 3. , 4.5, 1.5],\n",
              "       [5.8, 2.7, 4.1, 1. ],\n",
              "       [6.2, 2.2, 4.5, 1.5],\n",
              "       [5.6, 2.5, 3.9, 1.1],\n",
              "       [5.9, 3.2, 4.8, 1.8],\n",
              "       [6.1, 2.8, 4. , 1.3],\n",
              "       [6.3, 2.5, 4.9, 1.5],\n",
              "       [6.1, 2.8, 4.7, 1.2],\n",
              "       [6.4, 2.9, 4.3, 1.3],\n",
              "       [6.6, 3. , 4.4, 1.4],\n",
              "       [6.8, 2.8, 4.8, 1.4],\n",
              "       [6.7, 3. , 5. , 1.7],\n",
              "       [6. , 2.9, 4.5, 1.5],\n",
              "       [5.7, 2.6, 3.5, 1. ],\n",
              "       [5.5, 2.4, 3.8, 1.1],\n",
              "       [5.5, 2.4, 3.7, 1. ],\n",
              "       [5.8, 2.7, 3.9, 1.2],\n",
              "       [6. , 2.7, 5.1, 1.6],\n",
              "       [5.4, 3. , 4.5, 1.5],\n",
              "       [6. , 3.4, 4.5, 1.6],\n",
              "       [6.7, 3.1, 4.7, 1.5],\n",
              "       [6.3, 2.3, 4.4, 1.3],\n",
              "       [5.6, 3. , 4.1, 1.3],\n",
              "       [5.5, 2.5, 4. , 1.3],\n",
              "       [5.5, 2.6, 4.4, 1.2],\n",
              "       [6.1, 3. , 4.6, 1.4],\n",
              "       [5.8, 2.6, 4. , 1.2],\n",
              "       [5. , 2.3, 3.3, 1. ],\n",
              "       [5.6, 2.7, 4.2, 1.3],\n",
              "       [5.7, 3. , 4.2, 1.2],\n",
              "       [5.7, 2.9, 4.2, 1.3],\n",
              "       [6.2, 2.9, 4.3, 1.3],\n",
              "       [5.1, 2.5, 3. , 1.1],\n",
              "       [5.7, 2.8, 4.1, 1.3],\n",
              "       [6.3, 3.3, 6. , 2.5],\n",
              "       [5.8, 2.7, 5.1, 1.9],\n",
              "       [7.1, 3. , 5.9, 2.1],\n",
              "       [6.3, 2.9, 5.6, 1.8],\n",
              "       [6.5, 3. , 5.8, 2.2],\n",
              "       [7.6, 3. , 6.6, 2.1],\n",
              "       [4.9, 2.5, 4.5, 1.7],\n",
              "       [7.3, 2.9, 6.3, 1.8],\n",
              "       [6.7, 2.5, 5.8, 1.8],\n",
              "       [7.2, 3.6, 6.1, 2.5],\n",
              "       [6.5, 3.2, 5.1, 2. ],\n",
              "       [6.4, 2.7, 5.3, 1.9],\n",
              "       [6.8, 3. , 5.5, 2.1],\n",
              "       [5.7, 2.5, 5. , 2. ],\n",
              "       [5.8, 2.8, 5.1, 2.4],\n",
              "       [6.4, 3.2, 5.3, 2.3],\n",
              "       [6.5, 3. , 5.5, 1.8],\n",
              "       [7.7, 3.8, 6.7, 2.2],\n",
              "       [7.7, 2.6, 6.9, 2.3],\n",
              "       [6. , 2.2, 5. , 1.5],\n",
              "       [6.9, 3.2, 5.7, 2.3],\n",
              "       [5.6, 2.8, 4.9, 2. ],\n",
              "       [7.7, 2.8, 6.7, 2. ],\n",
              "       [6.3, 2.7, 4.9, 1.8],\n",
              "       [6.7, 3.3, 5.7, 2.1],\n",
              "       [7.2, 3.2, 6. , 1.8],\n",
              "       [6.2, 2.8, 4.8, 1.8],\n",
              "       [6.1, 3. , 4.9, 1.8],\n",
              "       [6.4, 2.8, 5.6, 2.1],\n",
              "       [7.2, 3. , 5.8, 1.6],\n",
              "       [7.4, 2.8, 6.1, 1.9],\n",
              "       [7.9, 3.8, 6.4, 2. ],\n",
              "       [6.4, 2.8, 5.6, 2.2],\n",
              "       [6.3, 2.8, 5.1, 1.5],\n",
              "       [6.1, 2.6, 5.6, 1.4],\n",
              "       [7.7, 3. , 6.1, 2.3],\n",
              "       [6.3, 3.4, 5.6, 2.4],\n",
              "       [6.4, 3.1, 5.5, 1.8],\n",
              "       [6. , 3. , 4.8, 1.8],\n",
              "       [6.9, 3.1, 5.4, 2.1],\n",
              "       [6.7, 3.1, 5.6, 2.4],\n",
              "       [6.9, 3.1, 5.1, 2.3],\n",
              "       [5.8, 2.7, 5.1, 1.9],\n",
              "       [6.8, 3.2, 5.9, 2.3],\n",
              "       [6.7, 3.3, 5.7, 2.5],\n",
              "       [6.7, 3. , 5.2, 2.3],\n",
              "       [6.3, 2.5, 5. , 1.9],\n",
              "       [6.5, 3. , 5.2, 2. ],\n",
              "       [6.2, 3.4, 5.4, 2.3],\n",
              "       [5.9, 3. , 5.1, 1.8]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xLfr_z4LBOD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = iris.target"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Go76xmmULBON",
        "colab_type": "code",
        "outputId": "593b48e2-c28d-4965-806e-11f7bc472e3f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "y"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FSxuOFOdLBPP",
        "colab_type": "code",
        "outputId": "3cd88c5c-1554-47a3-a0f8-5bd6281029f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "from keras.utils import to_categorical"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJwfp_V5LBPS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = to_categorical(y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ntmZA6iLLBPX",
        "colab_type": "code",
        "outputId": "32bb63a8-8722-464a-a43c-ea27e371d09f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(150, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s9DQAzU5LBPb",
        "colab_type": "code",
        "outputId": "5e82e82d-ac36-465a-db2b-81b577be5cfc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "y"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98r3pQR9LBPg",
        "colab_type": "text"
      },
      "source": [
        "## Split the Data into Training and Test\n",
        "\n",
        "Its time to split the data into a train/test set. Keep in mind, sometimes people like to split 3 ways, train/test/validation. We'll keep things simple for now. **Remember to check out the video explanation as to why we split and what all the parameters mean!**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ppk5Yb9MLBPh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y27rPn2wLBPo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwDBt3xNLBPt",
        "colab_type": "code",
        "outputId": "540cdde9-e8fc-48ea-a7fb-1931f8a547c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "X_train"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[5.7, 2.9, 4.2, 1.3],\n",
              "       [7.6, 3. , 6.6, 2.1],\n",
              "       [5.6, 3. , 4.5, 1.5],\n",
              "       [5.1, 3.5, 1.4, 0.2],\n",
              "       [7.7, 2.8, 6.7, 2. ],\n",
              "       [5.8, 2.7, 4.1, 1. ],\n",
              "       [5.2, 3.4, 1.4, 0.2],\n",
              "       [5. , 3.5, 1.3, 0.3],\n",
              "       [5.1, 3.8, 1.9, 0.4],\n",
              "       [5. , 2. , 3.5, 1. ],\n",
              "       [6.3, 2.7, 4.9, 1.8],\n",
              "       [4.8, 3.4, 1.9, 0.2],\n",
              "       [5. , 3. , 1.6, 0.2],\n",
              "       [5.1, 3.3, 1.7, 0.5],\n",
              "       [5.6, 2.7, 4.2, 1.3],\n",
              "       [5.1, 3.4, 1.5, 0.2],\n",
              "       [5.7, 3. , 4.2, 1.2],\n",
              "       [7.7, 3.8, 6.7, 2.2],\n",
              "       [4.6, 3.2, 1.4, 0.2],\n",
              "       [6.2, 2.9, 4.3, 1.3],\n",
              "       [5.7, 2.5, 5. , 2. ],\n",
              "       [5.5, 4.2, 1.4, 0.2],\n",
              "       [6. , 3. , 4.8, 1.8],\n",
              "       [5.8, 2.7, 5.1, 1.9],\n",
              "       [6. , 2.2, 4. , 1. ],\n",
              "       [5.4, 3. , 4.5, 1.5],\n",
              "       [6.2, 3.4, 5.4, 2.3],\n",
              "       [5.5, 2.3, 4. , 1.3],\n",
              "       [5.4, 3.9, 1.7, 0.4],\n",
              "       [5. , 2.3, 3.3, 1. ],\n",
              "       [6.4, 2.7, 5.3, 1.9],\n",
              "       [5. , 3.3, 1.4, 0.2],\n",
              "       [5. , 3.2, 1.2, 0.2],\n",
              "       [5.5, 2.4, 3.8, 1.1],\n",
              "       [6.7, 3. , 5. , 1.7],\n",
              "       [4.9, 3.1, 1.5, 0.2],\n",
              "       [5.8, 2.8, 5.1, 2.4],\n",
              "       [5. , 3.4, 1.5, 0.2],\n",
              "       [5. , 3.5, 1.6, 0.6],\n",
              "       [5.9, 3.2, 4.8, 1.8],\n",
              "       [5.1, 2.5, 3. , 1.1],\n",
              "       [6.9, 3.2, 5.7, 2.3],\n",
              "       [6. , 2.7, 5.1, 1.6],\n",
              "       [6.1, 2.6, 5.6, 1.4],\n",
              "       [7.7, 3. , 6.1, 2.3],\n",
              "       [5.5, 2.5, 4. , 1.3],\n",
              "       [4.4, 2.9, 1.4, 0.2],\n",
              "       [4.3, 3. , 1.1, 0.1],\n",
              "       [6. , 2.2, 5. , 1.5],\n",
              "       [7.2, 3.2, 6. , 1.8],\n",
              "       [4.6, 3.1, 1.5, 0.2],\n",
              "       [5.1, 3.5, 1.4, 0.3],\n",
              "       [4.4, 3. , 1.3, 0.2],\n",
              "       [6.3, 2.5, 4.9, 1.5],\n",
              "       [6.3, 3.4, 5.6, 2.4],\n",
              "       [4.6, 3.4, 1.4, 0.3],\n",
              "       [6.8, 3. , 5.5, 2.1],\n",
              "       [6.3, 3.3, 6. , 2.5],\n",
              "       [4.7, 3.2, 1.3, 0.2],\n",
              "       [6.1, 2.9, 4.7, 1.4],\n",
              "       [6.5, 2.8, 4.6, 1.5],\n",
              "       [6.2, 2.8, 4.8, 1.8],\n",
              "       [7. , 3.2, 4.7, 1.4],\n",
              "       [6.4, 3.2, 5.3, 2.3],\n",
              "       [5.1, 3.8, 1.6, 0.2],\n",
              "       [6.9, 3.1, 5.4, 2.1],\n",
              "       [5.9, 3. , 4.2, 1.5],\n",
              "       [6.5, 3. , 5.2, 2. ],\n",
              "       [5.7, 2.6, 3.5, 1. ],\n",
              "       [5.2, 2.7, 3.9, 1.4],\n",
              "       [6.1, 3. , 4.6, 1.4],\n",
              "       [4.5, 2.3, 1.3, 0.3],\n",
              "       [6.6, 2.9, 4.6, 1.3],\n",
              "       [5.5, 2.6, 4.4, 1.2],\n",
              "       [5.3, 3.7, 1.5, 0.2],\n",
              "       [5.6, 3. , 4.1, 1.3],\n",
              "       [7.3, 2.9, 6.3, 1.8],\n",
              "       [6.7, 3.3, 5.7, 2.1],\n",
              "       [5.1, 3.7, 1.5, 0.4],\n",
              "       [4.9, 2.4, 3.3, 1. ],\n",
              "       [6.7, 3.3, 5.7, 2.5],\n",
              "       [7.2, 3. , 5.8, 1.6],\n",
              "       [4.9, 3.6, 1.4, 0.1],\n",
              "       [6.7, 3.1, 5.6, 2.4],\n",
              "       [4.9, 3. , 1.4, 0.2],\n",
              "       [6.9, 3.1, 4.9, 1.5],\n",
              "       [7.4, 2.8, 6.1, 1.9],\n",
              "       [6.3, 2.9, 5.6, 1.8],\n",
              "       [5.7, 2.8, 4.1, 1.3],\n",
              "       [6.5, 3. , 5.5, 1.8],\n",
              "       [6.3, 2.3, 4.4, 1.3],\n",
              "       [6.4, 2.9, 4.3, 1.3],\n",
              "       [5.6, 2.8, 4.9, 2. ],\n",
              "       [5.9, 3. , 5.1, 1.8],\n",
              "       [5.4, 3.4, 1.7, 0.2],\n",
              "       [6.1, 2.8, 4. , 1.3],\n",
              "       [4.9, 2.5, 4.5, 1.7],\n",
              "       [5.8, 4. , 1.2, 0.2],\n",
              "       [5.8, 2.6, 4. , 1.2],\n",
              "       [7.1, 3. , 5.9, 2.1]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RuxRIUVCLBPx",
        "colab_type": "code",
        "outputId": "c17fa84e-5b82-4b19-dba8-c4297075d85e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        }
      },
      "source": [
        "X_test"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[6.1, 2.8, 4.7, 1.2],\n",
              "       [5.7, 3.8, 1.7, 0.3],\n",
              "       [7.7, 2.6, 6.9, 2.3],\n",
              "       [6. , 2.9, 4.5, 1.5],\n",
              "       [6.8, 2.8, 4.8, 1.4],\n",
              "       [5.4, 3.4, 1.5, 0.4],\n",
              "       [5.6, 2.9, 3.6, 1.3],\n",
              "       [6.9, 3.1, 5.1, 2.3],\n",
              "       [6.2, 2.2, 4.5, 1.5],\n",
              "       [5.8, 2.7, 3.9, 1.2],\n",
              "       [6.5, 3.2, 5.1, 2. ],\n",
              "       [4.8, 3. , 1.4, 0.1],\n",
              "       [5.5, 3.5, 1.3, 0.2],\n",
              "       [4.9, 3.1, 1.5, 0.1],\n",
              "       [5.1, 3.8, 1.5, 0.3],\n",
              "       [6.3, 3.3, 4.7, 1.6],\n",
              "       [6.5, 3. , 5.8, 2.2],\n",
              "       [5.6, 2.5, 3.9, 1.1],\n",
              "       [5.7, 2.8, 4.5, 1.3],\n",
              "       [6.4, 2.8, 5.6, 2.2],\n",
              "       [4.7, 3.2, 1.6, 0.2],\n",
              "       [6.1, 3. , 4.9, 1.8],\n",
              "       [5. , 3.4, 1.6, 0.4],\n",
              "       [6.4, 2.8, 5.6, 2.1],\n",
              "       [7.9, 3.8, 6.4, 2. ],\n",
              "       [6.7, 3. , 5.2, 2.3],\n",
              "       [6.7, 2.5, 5.8, 1.8],\n",
              "       [6.8, 3.2, 5.9, 2.3],\n",
              "       [4.8, 3. , 1.4, 0.3],\n",
              "       [4.8, 3.1, 1.6, 0.2],\n",
              "       [4.6, 3.6, 1. , 0.2],\n",
              "       [5.7, 4.4, 1.5, 0.4],\n",
              "       [6.7, 3.1, 4.4, 1.4],\n",
              "       [4.8, 3.4, 1.6, 0.2],\n",
              "       [4.4, 3.2, 1.3, 0.2],\n",
              "       [6.3, 2.5, 5. , 1.9],\n",
              "       [6.4, 3.2, 4.5, 1.5],\n",
              "       [5.2, 3.5, 1.5, 0.2],\n",
              "       [5. , 3.6, 1.4, 0.2],\n",
              "       [5.2, 4.1, 1.5, 0.1],\n",
              "       [5.8, 2.7, 5.1, 1.9],\n",
              "       [6. , 3.4, 4.5, 1.6],\n",
              "       [6.7, 3.1, 4.7, 1.5],\n",
              "       [5.4, 3.9, 1.3, 0.4],\n",
              "       [5.4, 3.7, 1.5, 0.2],\n",
              "       [5.5, 2.4, 3.7, 1. ],\n",
              "       [6.3, 2.8, 5.1, 1.5],\n",
              "       [6.4, 3.1, 5.5, 1.8],\n",
              "       [6.6, 3. , 4.4, 1.4],\n",
              "       [7.2, 3.6, 6.1, 2.5]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NrDGuL8uLBP0",
        "colab_type": "code",
        "outputId": "ebcac97f-c5ed-4ff9-f2bb-3353123bb36f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "y_train"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQHtgqAYLBP7",
        "colab_type": "code",
        "outputId": "83ae2ed6-1a17-42c9-ba25-93d3905f7ff2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        }
      },
      "source": [
        "y_test"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WpfqxOjtLBQA",
        "colab_type": "text"
      },
      "source": [
        "## Standardizing the Data\n",
        "\n",
        "Usually when using Neural Networks, you will get better performance when you standardize the data. Standardization just means normalizing the values to all fit between a certain range, like 0-1, or -1 to 1.\n",
        "\n",
        "The scikit learn library also provides a nice function for this.\n",
        "\n",
        "http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FacsW9p6LBQC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJy8pE-_LBQG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scaler_object = MinMaxScaler()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zMaB8P_2LBQM",
        "colab_type": "code",
        "outputId": "dcd27ac0-5320-4397-eae6-2ec4fcf45c9f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "scaler_object.fit(X_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MinMaxScaler(copy=True, feature_range=(0, 1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLLbLj9fLBQP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scaled_X_train = scaler_object.transform(X_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVcdtztuLBQl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scaled_X_test = scaler_object.transform(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SH29tMq7LBRi",
        "colab_type": "text"
      },
      "source": [
        "Ok, now we have the data scaled!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0T-4-KOLBRn",
        "colab_type": "code",
        "outputId": "8f0a3b40-1f3f-44ea-fb70-2e1595e85430",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_train.max()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7.7"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VFqRtbxWLBR0",
        "colab_type": "code",
        "outputId": "eb14102a-a525-4c51-d0dc-de3fcc40980b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "scaled_X_train.max()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EleYbTgjLBSD",
        "colab_type": "code",
        "outputId": "5b44cc89-e572-4719-c0c7-48c5affe6896",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "X_train"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[5.7, 2.9, 4.2, 1.3],\n",
              "       [7.6, 3. , 6.6, 2.1],\n",
              "       [5.6, 3. , 4.5, 1.5],\n",
              "       [5.1, 3.5, 1.4, 0.2],\n",
              "       [7.7, 2.8, 6.7, 2. ],\n",
              "       [5.8, 2.7, 4.1, 1. ],\n",
              "       [5.2, 3.4, 1.4, 0.2],\n",
              "       [5. , 3.5, 1.3, 0.3],\n",
              "       [5.1, 3.8, 1.9, 0.4],\n",
              "       [5. , 2. , 3.5, 1. ],\n",
              "       [6.3, 2.7, 4.9, 1.8],\n",
              "       [4.8, 3.4, 1.9, 0.2],\n",
              "       [5. , 3. , 1.6, 0.2],\n",
              "       [5.1, 3.3, 1.7, 0.5],\n",
              "       [5.6, 2.7, 4.2, 1.3],\n",
              "       [5.1, 3.4, 1.5, 0.2],\n",
              "       [5.7, 3. , 4.2, 1.2],\n",
              "       [7.7, 3.8, 6.7, 2.2],\n",
              "       [4.6, 3.2, 1.4, 0.2],\n",
              "       [6.2, 2.9, 4.3, 1.3],\n",
              "       [5.7, 2.5, 5. , 2. ],\n",
              "       [5.5, 4.2, 1.4, 0.2],\n",
              "       [6. , 3. , 4.8, 1.8],\n",
              "       [5.8, 2.7, 5.1, 1.9],\n",
              "       [6. , 2.2, 4. , 1. ],\n",
              "       [5.4, 3. , 4.5, 1.5],\n",
              "       [6.2, 3.4, 5.4, 2.3],\n",
              "       [5.5, 2.3, 4. , 1.3],\n",
              "       [5.4, 3.9, 1.7, 0.4],\n",
              "       [5. , 2.3, 3.3, 1. ],\n",
              "       [6.4, 2.7, 5.3, 1.9],\n",
              "       [5. , 3.3, 1.4, 0.2],\n",
              "       [5. , 3.2, 1.2, 0.2],\n",
              "       [5.5, 2.4, 3.8, 1.1],\n",
              "       [6.7, 3. , 5. , 1.7],\n",
              "       [4.9, 3.1, 1.5, 0.2],\n",
              "       [5.8, 2.8, 5.1, 2.4],\n",
              "       [5. , 3.4, 1.5, 0.2],\n",
              "       [5. , 3.5, 1.6, 0.6],\n",
              "       [5.9, 3.2, 4.8, 1.8],\n",
              "       [5.1, 2.5, 3. , 1.1],\n",
              "       [6.9, 3.2, 5.7, 2.3],\n",
              "       [6. , 2.7, 5.1, 1.6],\n",
              "       [6.1, 2.6, 5.6, 1.4],\n",
              "       [7.7, 3. , 6.1, 2.3],\n",
              "       [5.5, 2.5, 4. , 1.3],\n",
              "       [4.4, 2.9, 1.4, 0.2],\n",
              "       [4.3, 3. , 1.1, 0.1],\n",
              "       [6. , 2.2, 5. , 1.5],\n",
              "       [7.2, 3.2, 6. , 1.8],\n",
              "       [4.6, 3.1, 1.5, 0.2],\n",
              "       [5.1, 3.5, 1.4, 0.3],\n",
              "       [4.4, 3. , 1.3, 0.2],\n",
              "       [6.3, 2.5, 4.9, 1.5],\n",
              "       [6.3, 3.4, 5.6, 2.4],\n",
              "       [4.6, 3.4, 1.4, 0.3],\n",
              "       [6.8, 3. , 5.5, 2.1],\n",
              "       [6.3, 3.3, 6. , 2.5],\n",
              "       [4.7, 3.2, 1.3, 0.2],\n",
              "       [6.1, 2.9, 4.7, 1.4],\n",
              "       [6.5, 2.8, 4.6, 1.5],\n",
              "       [6.2, 2.8, 4.8, 1.8],\n",
              "       [7. , 3.2, 4.7, 1.4],\n",
              "       [6.4, 3.2, 5.3, 2.3],\n",
              "       [5.1, 3.8, 1.6, 0.2],\n",
              "       [6.9, 3.1, 5.4, 2.1],\n",
              "       [5.9, 3. , 4.2, 1.5],\n",
              "       [6.5, 3. , 5.2, 2. ],\n",
              "       [5.7, 2.6, 3.5, 1. ],\n",
              "       [5.2, 2.7, 3.9, 1.4],\n",
              "       [6.1, 3. , 4.6, 1.4],\n",
              "       [4.5, 2.3, 1.3, 0.3],\n",
              "       [6.6, 2.9, 4.6, 1.3],\n",
              "       [5.5, 2.6, 4.4, 1.2],\n",
              "       [5.3, 3.7, 1.5, 0.2],\n",
              "       [5.6, 3. , 4.1, 1.3],\n",
              "       [7.3, 2.9, 6.3, 1.8],\n",
              "       [6.7, 3.3, 5.7, 2.1],\n",
              "       [5.1, 3.7, 1.5, 0.4],\n",
              "       [4.9, 2.4, 3.3, 1. ],\n",
              "       [6.7, 3.3, 5.7, 2.5],\n",
              "       [7.2, 3. , 5.8, 1.6],\n",
              "       [4.9, 3.6, 1.4, 0.1],\n",
              "       [6.7, 3.1, 5.6, 2.4],\n",
              "       [4.9, 3. , 1.4, 0.2],\n",
              "       [6.9, 3.1, 4.9, 1.5],\n",
              "       [7.4, 2.8, 6.1, 1.9],\n",
              "       [6.3, 2.9, 5.6, 1.8],\n",
              "       [5.7, 2.8, 4.1, 1.3],\n",
              "       [6.5, 3. , 5.5, 1.8],\n",
              "       [6.3, 2.3, 4.4, 1.3],\n",
              "       [6.4, 2.9, 4.3, 1.3],\n",
              "       [5.6, 2.8, 4.9, 2. ],\n",
              "       [5.9, 3. , 5.1, 1.8],\n",
              "       [5.4, 3.4, 1.7, 0.2],\n",
              "       [6.1, 2.8, 4. , 1.3],\n",
              "       [4.9, 2.5, 4.5, 1.7],\n",
              "       [5.8, 4. , 1.2, 0.2],\n",
              "       [5.8, 2.6, 4. , 1.2],\n",
              "       [7.1, 3. , 5.9, 2.1]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "km1GGKhHLBSJ",
        "colab_type": "code",
        "outputId": "09b92c1c-ea0d-4739-a690-78be34cbea51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "scaled_X_train"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.41176471, 0.40909091, 0.55357143, 0.5       ],\n",
              "       [0.97058824, 0.45454545, 0.98214286, 0.83333333],\n",
              "       [0.38235294, 0.45454545, 0.60714286, 0.58333333],\n",
              "       [0.23529412, 0.68181818, 0.05357143, 0.04166667],\n",
              "       [1.        , 0.36363636, 1.        , 0.79166667],\n",
              "       [0.44117647, 0.31818182, 0.53571429, 0.375     ],\n",
              "       [0.26470588, 0.63636364, 0.05357143, 0.04166667],\n",
              "       [0.20588235, 0.68181818, 0.03571429, 0.08333333],\n",
              "       [0.23529412, 0.81818182, 0.14285714, 0.125     ],\n",
              "       [0.20588235, 0.        , 0.42857143, 0.375     ],\n",
              "       [0.58823529, 0.31818182, 0.67857143, 0.70833333],\n",
              "       [0.14705882, 0.63636364, 0.14285714, 0.04166667],\n",
              "       [0.20588235, 0.45454545, 0.08928571, 0.04166667],\n",
              "       [0.23529412, 0.59090909, 0.10714286, 0.16666667],\n",
              "       [0.38235294, 0.31818182, 0.55357143, 0.5       ],\n",
              "       [0.23529412, 0.63636364, 0.07142857, 0.04166667],\n",
              "       [0.41176471, 0.45454545, 0.55357143, 0.45833333],\n",
              "       [1.        , 0.81818182, 1.        , 0.875     ],\n",
              "       [0.08823529, 0.54545455, 0.05357143, 0.04166667],\n",
              "       [0.55882353, 0.40909091, 0.57142857, 0.5       ],\n",
              "       [0.41176471, 0.22727273, 0.69642857, 0.79166667],\n",
              "       [0.35294118, 1.        , 0.05357143, 0.04166667],\n",
              "       [0.5       , 0.45454545, 0.66071429, 0.70833333],\n",
              "       [0.44117647, 0.31818182, 0.71428571, 0.75      ],\n",
              "       [0.5       , 0.09090909, 0.51785714, 0.375     ],\n",
              "       [0.32352941, 0.45454545, 0.60714286, 0.58333333],\n",
              "       [0.55882353, 0.63636364, 0.76785714, 0.91666667],\n",
              "       [0.35294118, 0.13636364, 0.51785714, 0.5       ],\n",
              "       [0.32352941, 0.86363636, 0.10714286, 0.125     ],\n",
              "       [0.20588235, 0.13636364, 0.39285714, 0.375     ],\n",
              "       [0.61764706, 0.31818182, 0.75      , 0.75      ],\n",
              "       [0.20588235, 0.59090909, 0.05357143, 0.04166667],\n",
              "       [0.20588235, 0.54545455, 0.01785714, 0.04166667],\n",
              "       [0.35294118, 0.18181818, 0.48214286, 0.41666667],\n",
              "       [0.70588235, 0.45454545, 0.69642857, 0.66666667],\n",
              "       [0.17647059, 0.5       , 0.07142857, 0.04166667],\n",
              "       [0.44117647, 0.36363636, 0.71428571, 0.95833333],\n",
              "       [0.20588235, 0.63636364, 0.07142857, 0.04166667],\n",
              "       [0.20588235, 0.68181818, 0.08928571, 0.20833333],\n",
              "       [0.47058824, 0.54545455, 0.66071429, 0.70833333],\n",
              "       [0.23529412, 0.22727273, 0.33928571, 0.41666667],\n",
              "       [0.76470588, 0.54545455, 0.82142857, 0.91666667],\n",
              "       [0.5       , 0.31818182, 0.71428571, 0.625     ],\n",
              "       [0.52941176, 0.27272727, 0.80357143, 0.54166667],\n",
              "       [1.        , 0.45454545, 0.89285714, 0.91666667],\n",
              "       [0.35294118, 0.22727273, 0.51785714, 0.5       ],\n",
              "       [0.02941176, 0.40909091, 0.05357143, 0.04166667],\n",
              "       [0.        , 0.45454545, 0.        , 0.        ],\n",
              "       [0.5       , 0.09090909, 0.69642857, 0.58333333],\n",
              "       [0.85294118, 0.54545455, 0.875     , 0.70833333],\n",
              "       [0.08823529, 0.5       , 0.07142857, 0.04166667],\n",
              "       [0.23529412, 0.68181818, 0.05357143, 0.08333333],\n",
              "       [0.02941176, 0.45454545, 0.03571429, 0.04166667],\n",
              "       [0.58823529, 0.22727273, 0.67857143, 0.58333333],\n",
              "       [0.58823529, 0.63636364, 0.80357143, 0.95833333],\n",
              "       [0.08823529, 0.63636364, 0.05357143, 0.08333333],\n",
              "       [0.73529412, 0.45454545, 0.78571429, 0.83333333],\n",
              "       [0.58823529, 0.59090909, 0.875     , 1.        ],\n",
              "       [0.11764706, 0.54545455, 0.03571429, 0.04166667],\n",
              "       [0.52941176, 0.40909091, 0.64285714, 0.54166667],\n",
              "       [0.64705882, 0.36363636, 0.625     , 0.58333333],\n",
              "       [0.55882353, 0.36363636, 0.66071429, 0.70833333],\n",
              "       [0.79411765, 0.54545455, 0.64285714, 0.54166667],\n",
              "       [0.61764706, 0.54545455, 0.75      , 0.91666667],\n",
              "       [0.23529412, 0.81818182, 0.08928571, 0.04166667],\n",
              "       [0.76470588, 0.5       , 0.76785714, 0.83333333],\n",
              "       [0.47058824, 0.45454545, 0.55357143, 0.58333333],\n",
              "       [0.64705882, 0.45454545, 0.73214286, 0.79166667],\n",
              "       [0.41176471, 0.27272727, 0.42857143, 0.375     ],\n",
              "       [0.26470588, 0.31818182, 0.5       , 0.54166667],\n",
              "       [0.52941176, 0.45454545, 0.625     , 0.54166667],\n",
              "       [0.05882353, 0.13636364, 0.03571429, 0.08333333],\n",
              "       [0.67647059, 0.40909091, 0.625     , 0.5       ],\n",
              "       [0.35294118, 0.27272727, 0.58928571, 0.45833333],\n",
              "       [0.29411765, 0.77272727, 0.07142857, 0.04166667],\n",
              "       [0.38235294, 0.45454545, 0.53571429, 0.5       ],\n",
              "       [0.88235294, 0.40909091, 0.92857143, 0.70833333],\n",
              "       [0.70588235, 0.59090909, 0.82142857, 0.83333333],\n",
              "       [0.23529412, 0.77272727, 0.07142857, 0.125     ],\n",
              "       [0.17647059, 0.18181818, 0.39285714, 0.375     ],\n",
              "       [0.70588235, 0.59090909, 0.82142857, 1.        ],\n",
              "       [0.85294118, 0.45454545, 0.83928571, 0.625     ],\n",
              "       [0.17647059, 0.72727273, 0.05357143, 0.        ],\n",
              "       [0.70588235, 0.5       , 0.80357143, 0.95833333],\n",
              "       [0.17647059, 0.45454545, 0.05357143, 0.04166667],\n",
              "       [0.76470588, 0.5       , 0.67857143, 0.58333333],\n",
              "       [0.91176471, 0.36363636, 0.89285714, 0.75      ],\n",
              "       [0.58823529, 0.40909091, 0.80357143, 0.70833333],\n",
              "       [0.41176471, 0.36363636, 0.53571429, 0.5       ],\n",
              "       [0.64705882, 0.45454545, 0.78571429, 0.70833333],\n",
              "       [0.58823529, 0.13636364, 0.58928571, 0.5       ],\n",
              "       [0.61764706, 0.40909091, 0.57142857, 0.5       ],\n",
              "       [0.38235294, 0.36363636, 0.67857143, 0.79166667],\n",
              "       [0.47058824, 0.45454545, 0.71428571, 0.70833333],\n",
              "       [0.32352941, 0.63636364, 0.10714286, 0.04166667],\n",
              "       [0.52941176, 0.36363636, 0.51785714, 0.5       ],\n",
              "       [0.17647059, 0.22727273, 0.60714286, 0.66666667],\n",
              "       [0.44117647, 0.90909091, 0.01785714, 0.04166667],\n",
              "       [0.44117647, 0.27272727, 0.51785714, 0.45833333],\n",
              "       [0.82352941, 0.45454545, 0.85714286, 0.83333333]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQSZ91ZpLBSQ",
        "colab_type": "text"
      },
      "source": [
        "## Building the Network with Keras\n",
        "\n",
        "Let's build a simple neural network!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AU8l3TT8LBSS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTclQpGhLBSW",
        "colab_type": "code",
        "outputId": "8c8f2dd1-4a5d-4c73-b7ec-dc7cdbbd285d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(8, input_dim=4, activation='relu'))\n",
        "model.add(Dense(8, input_dim=4, activation='relu'))\n",
        "model.add(Dense(3, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bx7ejslJLBSd",
        "colab_type": "code",
        "outputId": "6eeafab1-0527-4c43-d61a-cfa10ab7bc05",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 8)                 40        \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 8)                 72        \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 3)                 27        \n",
            "=================================================================\n",
            "Total params: 139\n",
            "Trainable params: 139\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jpADWxfMLBSh",
        "colab_type": "text"
      },
      "source": [
        "## Fit (Train) the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m15z6Im-LBSi",
        "colab_type": "code",
        "outputId": "d180e87a-727d-4573-aad1-4777b57fd6a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Play around with number of epochs as well!\n",
        "model.fit(scaled_X_train,y_train,epochs=150, verbose=2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Epoch 1/150\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            " - 1s - loss: 1.0499 - acc: 0.3400\n",
            "Epoch 2/150\n",
            " - 0s - loss: 1.0417 - acc: 0.3400\n",
            "Epoch 3/150\n",
            " - 0s - loss: 1.0323 - acc: 0.3400\n",
            "Epoch 4/150\n",
            " - 0s - loss: 1.0236 - acc: 0.3400\n",
            "Epoch 5/150\n",
            " - 0s - loss: 1.0160 - acc: 0.3400\n",
            "Epoch 6/150\n",
            " - 0s - loss: 1.0078 - acc: 0.3400\n",
            "Epoch 7/150\n",
            " - 0s - loss: 1.0019 - acc: 0.3400\n",
            "Epoch 8/150\n",
            " - 0s - loss: 0.9956 - acc: 0.3400\n",
            "Epoch 9/150\n",
            " - 0s - loss: 0.9897 - acc: 0.3400\n",
            "Epoch 10/150\n",
            " - 0s - loss: 0.9845 - acc: 0.3400\n",
            "Epoch 11/150\n",
            " - 0s - loss: 0.9801 - acc: 0.3400\n",
            "Epoch 12/150\n",
            " - 0s - loss: 0.9753 - acc: 0.3500\n",
            "Epoch 13/150\n",
            " - 0s - loss: 0.9710 - acc: 0.3500\n",
            "Epoch 14/150\n",
            " - 0s - loss: 0.9665 - acc: 0.3500\n",
            "Epoch 15/150\n",
            " - 0s - loss: 0.9623 - acc: 0.3800\n",
            "Epoch 16/150\n",
            " - 0s - loss: 0.9568 - acc: 0.3900\n",
            "Epoch 17/150\n",
            " - 0s - loss: 0.9512 - acc: 0.4000\n",
            "Epoch 18/150\n",
            " - 0s - loss: 0.9452 - acc: 0.4100\n",
            "Epoch 19/150\n",
            " - 0s - loss: 0.9382 - acc: 0.4100\n",
            "Epoch 20/150\n",
            " - 0s - loss: 0.9308 - acc: 0.4400\n",
            "Epoch 21/150\n",
            " - 0s - loss: 0.9224 - acc: 0.4800\n",
            "Epoch 22/150\n",
            " - 0s - loss: 0.9133 - acc: 0.5000\n",
            "Epoch 23/150\n",
            " - 0s - loss: 0.9049 - acc: 0.5400\n",
            "Epoch 24/150\n",
            " - 0s - loss: 0.8965 - acc: 0.5700\n",
            "Epoch 25/150\n",
            " - 0s - loss: 0.8882 - acc: 0.5700\n",
            "Epoch 26/150\n",
            " - 0s - loss: 0.8804 - acc: 0.5900\n",
            "Epoch 27/150\n",
            " - 0s - loss: 0.8725 - acc: 0.6000\n",
            "Epoch 28/150\n",
            " - 0s - loss: 0.8649 - acc: 0.6200\n",
            "Epoch 29/150\n",
            " - 0s - loss: 0.8576 - acc: 0.6300\n",
            "Epoch 30/150\n",
            " - 0s - loss: 0.8507 - acc: 0.6300\n",
            "Epoch 31/150\n",
            " - 0s - loss: 0.8428 - acc: 0.6500\n",
            "Epoch 32/150\n",
            " - 0s - loss: 0.8350 - acc: 0.6600\n",
            "Epoch 33/150\n",
            " - 0s - loss: 0.8272 - acc: 0.6600\n",
            "Epoch 34/150\n",
            " - 0s - loss: 0.8187 - acc: 0.6600\n",
            "Epoch 35/150\n",
            " - 0s - loss: 0.8104 - acc: 0.6700\n",
            "Epoch 36/150\n",
            " - 0s - loss: 0.8029 - acc: 0.6800\n",
            "Epoch 37/150\n",
            " - 0s - loss: 0.7950 - acc: 0.6800\n",
            "Epoch 38/150\n",
            " - 0s - loss: 0.7870 - acc: 0.6800\n",
            "Epoch 39/150\n",
            " - 0s - loss: 0.7787 - acc: 0.6800\n",
            "Epoch 40/150\n",
            " - 0s - loss: 0.7710 - acc: 0.6800\n",
            "Epoch 41/150\n",
            " - 0s - loss: 0.7633 - acc: 0.6900\n",
            "Epoch 42/150\n",
            " - 0s - loss: 0.7556 - acc: 0.6900\n",
            "Epoch 43/150\n",
            " - 0s - loss: 0.7480 - acc: 0.6900\n",
            "Epoch 44/150\n",
            " - 0s - loss: 0.7404 - acc: 0.6900\n",
            "Epoch 45/150\n",
            " - 0s - loss: 0.7325 - acc: 0.6900\n",
            "Epoch 46/150\n",
            " - 0s - loss: 0.7248 - acc: 0.6900\n",
            "Epoch 47/150\n",
            " - 0s - loss: 0.7170 - acc: 0.6900\n",
            "Epoch 48/150\n",
            " - 0s - loss: 0.7094 - acc: 0.6900\n",
            "Epoch 49/150\n",
            " - 0s - loss: 0.7030 - acc: 0.6800\n",
            "Epoch 50/150\n",
            " - 0s - loss: 0.6959 - acc: 0.6800\n",
            "Epoch 51/150\n",
            " - 0s - loss: 0.6887 - acc: 0.6800\n",
            "Epoch 52/150\n",
            " - 0s - loss: 0.6817 - acc: 0.6800\n",
            "Epoch 53/150\n",
            " - 0s - loss: 0.6748 - acc: 0.6800\n",
            "Epoch 54/150\n",
            " - 0s - loss: 0.6684 - acc: 0.6800\n",
            "Epoch 55/150\n",
            " - 0s - loss: 0.6610 - acc: 0.6800\n",
            "Epoch 56/150\n",
            " - 0s - loss: 0.6543 - acc: 0.6800\n",
            "Epoch 57/150\n",
            " - 0s - loss: 0.6473 - acc: 0.6900\n",
            "Epoch 58/150\n",
            " - 0s - loss: 0.6406 - acc: 0.6900\n",
            "Epoch 59/150\n",
            " - 0s - loss: 0.6344 - acc: 0.6900\n",
            "Epoch 60/150\n",
            " - 0s - loss: 0.6284 - acc: 0.6900\n",
            "Epoch 61/150\n",
            " - 0s - loss: 0.6225 - acc: 0.6900\n",
            "Epoch 62/150\n",
            " - 0s - loss: 0.6165 - acc: 0.6900\n",
            "Epoch 63/150\n",
            " - 0s - loss: 0.6107 - acc: 0.6900\n",
            "Epoch 64/150\n",
            " - 0s - loss: 0.6052 - acc: 0.6900\n",
            "Epoch 65/150\n",
            " - 0s - loss: 0.5993 - acc: 0.7000\n",
            "Epoch 66/150\n",
            " - 0s - loss: 0.5937 - acc: 0.7000\n",
            "Epoch 67/150\n",
            " - 0s - loss: 0.5882 - acc: 0.7000\n",
            "Epoch 68/150\n",
            " - 0s - loss: 0.5831 - acc: 0.6900\n",
            "Epoch 69/150\n",
            " - 0s - loss: 0.5777 - acc: 0.7000\n",
            "Epoch 70/150\n",
            " - 0s - loss: 0.5726 - acc: 0.7000\n",
            "Epoch 71/150\n",
            " - 0s - loss: 0.5676 - acc: 0.7000\n",
            "Epoch 72/150\n",
            " - 0s - loss: 0.5624 - acc: 0.7000\n",
            "Epoch 73/150\n",
            " - 0s - loss: 0.5573 - acc: 0.7000\n",
            "Epoch 74/150\n",
            " - 0s - loss: 0.5526 - acc: 0.7000\n",
            "Epoch 75/150\n",
            " - 0s - loss: 0.5476 - acc: 0.7000\n",
            "Epoch 76/150\n",
            " - 0s - loss: 0.5428 - acc: 0.7000\n",
            "Epoch 77/150\n",
            " - 0s - loss: 0.5383 - acc: 0.7000\n",
            "Epoch 78/150\n",
            " - 0s - loss: 0.5339 - acc: 0.7000\n",
            "Epoch 79/150\n",
            " - 0s - loss: 0.5295 - acc: 0.7000\n",
            "Epoch 80/150\n",
            " - 0s - loss: 0.5254 - acc: 0.7000\n",
            "Epoch 81/150\n",
            " - 0s - loss: 0.5214 - acc: 0.7000\n",
            "Epoch 82/150\n",
            " - 0s - loss: 0.5176 - acc: 0.7000\n",
            "Epoch 83/150\n",
            " - 0s - loss: 0.5137 - acc: 0.7000\n",
            "Epoch 84/150\n",
            " - 0s - loss: 0.5096 - acc: 0.7000\n",
            "Epoch 85/150\n",
            " - 0s - loss: 0.5056 - acc: 0.7100\n",
            "Epoch 86/150\n",
            " - 0s - loss: 0.5018 - acc: 0.7100\n",
            "Epoch 87/150\n",
            " - 0s - loss: 0.4982 - acc: 0.7100\n",
            "Epoch 88/150\n",
            " - 0s - loss: 0.4948 - acc: 0.7100\n",
            "Epoch 89/150\n",
            " - 0s - loss: 0.4914 - acc: 0.7200\n",
            "Epoch 90/150\n",
            " - 0s - loss: 0.4878 - acc: 0.7300\n",
            "Epoch 91/150\n",
            " - 0s - loss: 0.4844 - acc: 0.7500\n",
            "Epoch 92/150\n",
            " - 0s - loss: 0.4811 - acc: 0.7600\n",
            "Epoch 93/150\n",
            " - 0s - loss: 0.4779 - acc: 0.7800\n",
            "Epoch 94/150\n",
            " - 0s - loss: 0.4749 - acc: 0.8100\n",
            "Epoch 95/150\n",
            " - 0s - loss: 0.4722 - acc: 0.8200\n",
            "Epoch 96/150\n",
            " - 0s - loss: 0.4690 - acc: 0.8200\n",
            "Epoch 97/150\n",
            " - 0s - loss: 0.4662 - acc: 0.8200\n",
            "Epoch 98/150\n",
            " - 0s - loss: 0.4632 - acc: 0.8200\n",
            "Epoch 99/150\n",
            " - 0s - loss: 0.4605 - acc: 0.7900\n",
            "Epoch 100/150\n",
            " - 0s - loss: 0.4581 - acc: 0.7800\n",
            "Epoch 101/150\n",
            " - 0s - loss: 0.4554 - acc: 0.7800\n",
            "Epoch 102/150\n",
            " - 0s - loss: 0.4531 - acc: 0.7800\n",
            "Epoch 103/150\n",
            " - 0s - loss: 0.4511 - acc: 0.7700\n",
            "Epoch 104/150\n",
            " - 0s - loss: 0.4482 - acc: 0.7800\n",
            "Epoch 105/150\n",
            " - 0s - loss: 0.4461 - acc: 0.8100\n",
            "Epoch 106/150\n",
            " - 0s - loss: 0.4427 - acc: 0.8200\n",
            "Epoch 107/150\n",
            " - 0s - loss: 0.4403 - acc: 0.8300\n",
            "Epoch 108/150\n",
            " - 0s - loss: 0.4378 - acc: 0.8300\n",
            "Epoch 109/150\n",
            " - 0s - loss: 0.4356 - acc: 0.8400\n",
            "Epoch 110/150\n",
            " - 0s - loss: 0.4334 - acc: 0.8300\n",
            "Epoch 111/150\n",
            " - 0s - loss: 0.4315 - acc: 0.8200\n",
            "Epoch 112/150\n",
            " - 0s - loss: 0.4298 - acc: 0.8200\n",
            "Epoch 113/150\n",
            " - 0s - loss: 0.4279 - acc: 0.8200\n",
            "Epoch 114/150\n",
            " - 0s - loss: 0.4254 - acc: 0.8200\n",
            "Epoch 115/150\n",
            " - 0s - loss: 0.4233 - acc: 0.8400\n",
            "Epoch 116/150\n",
            " - 0s - loss: 0.4205 - acc: 0.8500\n",
            "Epoch 117/150\n",
            " - 0s - loss: 0.4193 - acc: 0.8600\n",
            "Epoch 118/150\n",
            " - 0s - loss: 0.4166 - acc: 0.8800\n",
            "Epoch 119/150\n",
            " - 0s - loss: 0.4147 - acc: 0.8900\n",
            "Epoch 120/150\n",
            " - 0s - loss: 0.4128 - acc: 0.8900\n",
            "Epoch 121/150\n",
            " - 0s - loss: 0.4110 - acc: 0.9000\n",
            "Epoch 122/150\n",
            " - 0s - loss: 0.4090 - acc: 0.9000\n",
            "Epoch 123/150\n",
            " - 0s - loss: 0.4071 - acc: 0.9000\n",
            "Epoch 124/150\n",
            " - 0s - loss: 0.4053 - acc: 0.9000\n",
            "Epoch 125/150\n",
            " - 0s - loss: 0.4031 - acc: 0.9000\n",
            "Epoch 126/150\n",
            " - 0s - loss: 0.4018 - acc: 0.8900\n",
            "Epoch 127/150\n",
            " - 0s - loss: 0.4000 - acc: 0.8900\n",
            "Epoch 128/150\n",
            " - 0s - loss: 0.3986 - acc: 0.8600\n",
            "Epoch 129/150\n",
            " - 0s - loss: 0.3970 - acc: 0.8600\n",
            "Epoch 130/150\n",
            " - 0s - loss: 0.3950 - acc: 0.8700\n",
            "Epoch 131/150\n",
            " - 0s - loss: 0.3933 - acc: 0.8900\n",
            "Epoch 132/150\n",
            " - 0s - loss: 0.3916 - acc: 0.8900\n",
            "Epoch 133/150\n",
            " - 0s - loss: 0.3903 - acc: 0.8700\n",
            "Epoch 134/150\n",
            " - 0s - loss: 0.3888 - acc: 0.8600\n",
            "Epoch 135/150\n",
            " - 0s - loss: 0.3874 - acc: 0.8600\n",
            "Epoch 136/150\n",
            " - 0s - loss: 0.3854 - acc: 0.8800\n",
            "Epoch 137/150\n",
            " - 0s - loss: 0.3835 - acc: 0.8900\n",
            "Epoch 138/150\n",
            " - 0s - loss: 0.3817 - acc: 0.9000\n",
            "Epoch 139/150\n",
            " - 0s - loss: 0.3797 - acc: 0.9000\n",
            "Epoch 140/150\n",
            " - 0s - loss: 0.3783 - acc: 0.9000\n",
            "Epoch 141/150\n",
            " - 0s - loss: 0.3767 - acc: 0.9000\n",
            "Epoch 142/150\n",
            " - 0s - loss: 0.3751 - acc: 0.9100\n",
            "Epoch 143/150\n",
            " - 0s - loss: 0.3739 - acc: 0.9200\n",
            "Epoch 144/150\n",
            " - 0s - loss: 0.3721 - acc: 0.9200\n",
            "Epoch 145/150\n",
            " - 0s - loss: 0.3704 - acc: 0.9200\n",
            "Epoch 146/150\n",
            " - 0s - loss: 0.3689 - acc: 0.9200\n",
            "Epoch 147/150\n",
            " - 0s - loss: 0.3673 - acc: 0.9200\n",
            "Epoch 148/150\n",
            " - 0s - loss: 0.3659 - acc: 0.9300\n",
            "Epoch 149/150\n",
            " - 0s - loss: 0.3646 - acc: 0.9300\n",
            "Epoch 150/150\n",
            " - 0s - loss: 0.3633 - acc: 0.9300\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7a582b69e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AnQsh8FnLBSm",
        "colab_type": "text"
      },
      "source": [
        "## Predicting New Unseen Data\n",
        "\n",
        "Let's see how we did by predicting on **new data**. Remember, our model has **never** seen the test data that we scaled previously! This process is the exact same process you would use on totally brand new data. For example , a brand new bank note that you just analyzed ."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U98WUWisLBSn",
        "colab_type": "code",
        "outputId": "4910fa3a-dd33-4493-be7e-c9f1f7627510",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        }
      },
      "source": [
        "scaled_X_test"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.52941176,  0.36363636,  0.64285714,  0.45833333],\n",
              "       [ 0.41176471,  0.81818182,  0.10714286,  0.08333333],\n",
              "       [ 1.        ,  0.27272727,  1.03571429,  0.91666667],\n",
              "       [ 0.5       ,  0.40909091,  0.60714286,  0.58333333],\n",
              "       [ 0.73529412,  0.36363636,  0.66071429,  0.54166667],\n",
              "       [ 0.32352941,  0.63636364,  0.07142857,  0.125     ],\n",
              "       [ 0.38235294,  0.40909091,  0.44642857,  0.5       ],\n",
              "       [ 0.76470588,  0.5       ,  0.71428571,  0.91666667],\n",
              "       [ 0.55882353,  0.09090909,  0.60714286,  0.58333333],\n",
              "       [ 0.44117647,  0.31818182,  0.5       ,  0.45833333],\n",
              "       [ 0.64705882,  0.54545455,  0.71428571,  0.79166667],\n",
              "       [ 0.14705882,  0.45454545,  0.05357143,  0.        ],\n",
              "       [ 0.35294118,  0.68181818,  0.03571429,  0.04166667],\n",
              "       [ 0.17647059,  0.5       ,  0.07142857,  0.        ],\n",
              "       [ 0.23529412,  0.81818182,  0.07142857,  0.08333333],\n",
              "       [ 0.58823529,  0.59090909,  0.64285714,  0.625     ],\n",
              "       [ 0.64705882,  0.45454545,  0.83928571,  0.875     ],\n",
              "       [ 0.38235294,  0.22727273,  0.5       ,  0.41666667],\n",
              "       [ 0.41176471,  0.36363636,  0.60714286,  0.5       ],\n",
              "       [ 0.61764706,  0.36363636,  0.80357143,  0.875     ],\n",
              "       [ 0.11764706,  0.54545455,  0.08928571,  0.04166667],\n",
              "       [ 0.52941176,  0.45454545,  0.67857143,  0.70833333],\n",
              "       [ 0.20588235,  0.63636364,  0.08928571,  0.125     ],\n",
              "       [ 0.61764706,  0.36363636,  0.80357143,  0.83333333],\n",
              "       [ 1.05882353,  0.81818182,  0.94642857,  0.79166667],\n",
              "       [ 0.70588235,  0.45454545,  0.73214286,  0.91666667],\n",
              "       [ 0.70588235,  0.22727273,  0.83928571,  0.70833333],\n",
              "       [ 0.73529412,  0.54545455,  0.85714286,  0.91666667],\n",
              "       [ 0.14705882,  0.45454545,  0.05357143,  0.08333333],\n",
              "       [ 0.14705882,  0.5       ,  0.08928571,  0.04166667],\n",
              "       [ 0.08823529,  0.72727273, -0.01785714,  0.04166667],\n",
              "       [ 0.41176471,  1.09090909,  0.07142857,  0.125     ],\n",
              "       [ 0.70588235,  0.5       ,  0.58928571,  0.54166667],\n",
              "       [ 0.14705882,  0.63636364,  0.08928571,  0.04166667],\n",
              "       [ 0.02941176,  0.54545455,  0.03571429,  0.04166667],\n",
              "       [ 0.58823529,  0.22727273,  0.69642857,  0.75      ],\n",
              "       [ 0.61764706,  0.54545455,  0.60714286,  0.58333333],\n",
              "       [ 0.26470588,  0.68181818,  0.07142857,  0.04166667],\n",
              "       [ 0.20588235,  0.72727273,  0.05357143,  0.04166667],\n",
              "       [ 0.26470588,  0.95454545,  0.07142857,  0.        ],\n",
              "       [ 0.44117647,  0.31818182,  0.71428571,  0.75      ],\n",
              "       [ 0.5       ,  0.63636364,  0.60714286,  0.625     ],\n",
              "       [ 0.70588235,  0.5       ,  0.64285714,  0.58333333],\n",
              "       [ 0.32352941,  0.86363636,  0.03571429,  0.125     ],\n",
              "       [ 0.32352941,  0.77272727,  0.07142857,  0.04166667],\n",
              "       [ 0.35294118,  0.18181818,  0.46428571,  0.375     ],\n",
              "       [ 0.58823529,  0.36363636,  0.71428571,  0.58333333],\n",
              "       [ 0.61764706,  0.5       ,  0.78571429,  0.70833333],\n",
              "       [ 0.67647059,  0.45454545,  0.58928571,  0.54166667],\n",
              "       [ 0.85294118,  0.72727273,  0.89285714,  1.        ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zAUyviWBLBSv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Spits out probabilities by default.\n",
        "# model.predict(scaled_X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qpIiH06DLBS1",
        "colab_type": "code",
        "outputId": "5b2cf444-07d3-4c24-9d8c-cb8b33b5700d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "model.predict_classes(scaled_X_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 2, 1, 2, 0, 1, 2, 2, 1, 2, 0, 0, 0, 0, 1, 2, 1, 1, 2, 0, 2,\n",
              "       0, 2, 2, 2, 2, 2, 0, 0, 0, 0, 1, 0, 0, 2, 1, 0, 0, 0, 2, 1, 1, 0,\n",
              "       0, 1, 2, 2, 1, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "glo1YQFKnAcU",
        "colab_type": "code",
        "outputId": "9cf78eea-6fbc-422a-f0ba-9f50646b33e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# even though we converted y_test into one-hot encoding, we can revert it to categories,\n",
        "# to compare with these predictions\n",
        "\n",
        "y_test.argmax(axis=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 2, 1, 1, 0, 1, 2, 1, 1, 2, 0, 0, 0, 0, 1, 2, 1, 1, 2, 0, 2,\n",
              "       0, 2, 2, 2, 2, 2, 0, 0, 0, 0, 1, 0, 0, 2, 1, 0, 0, 0, 2, 1, 1, 0,\n",
              "       0, 1, 2, 2, 1, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JOFln-zYLBS7",
        "colab_type": "text"
      },
      "source": [
        "# Evaluating Model Performance\n",
        "\n",
        "So how well did we do? How do we actually measure \"well\". Is 95% accuracy good enough? It all depends on the situation. Also we need to take into account things like recall and precision. Make sure to watch the video discussion on classification evaluation before running this code!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tHWWsKRwLBS8",
        "colab_type": "code",
        "outputId": "9be67eeb-efce-4b56-e176-c8ac9a670399",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model.metrics_names"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['loss', 'acc']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8nRPIAdqLBTA",
        "colab_type": "code",
        "outputId": "f00dd315-ba27-46b8-81c9-86df27cc7d44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "model.evaluate(x=scaled_X_test,y=y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50/50 [==============================] - 0s 847us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3223077404499054, 0.96]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tKZAUJQ2LBTF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import confusion_matrix,classification_report, accuracy_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_yujRM2tLBTU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = model.predict_classes(scaled_X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BeRUykvHLBTX",
        "colab_type": "code",
        "outputId": "b1124191-1db8-4f5d-e527-3263db235e3f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "predictions"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 2, 1, 2, 0, 1, 2, 2, 1, 2, 0, 0, 0, 0, 1, 2, 1, 1, 2, 0, 2,\n",
              "       0, 2, 2, 2, 2, 2, 0, 0, 0, 0, 1, 0, 0, 2, 1, 0, 0, 0, 2, 1, 1, 0,\n",
              "       0, 1, 2, 2, 1, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1SL0g2DCLBTh",
        "colab_type": "code",
        "outputId": "28603584-02fb-4171-aac8-463a628b39e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "y_test.argmax(axis=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 2, 1, 1, 0, 1, 2, 1, 1, 2, 0, 0, 0, 0, 1, 2, 1, 1, 2, 0, 2,\n",
              "       0, 2, 2, 2, 2, 2, 0, 0, 0, 0, 1, 0, 0, 2, 1, 0, 0, 0, 2, 1, 1, 0,\n",
              "       0, 1, 2, 2, 1, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e1nY7T5fLBTu",
        "colab_type": "code",
        "outputId": "aee81ca0-6442-422d-8cf9-c1a70e244605",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "confusion_matrix(y_test.argmax(axis=1),predictions)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[19,  0,  0],\n",
              "       [ 0, 13,  2],\n",
              "       [ 0,  0, 16]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNjn4WuYLBUL",
        "colab_type": "code",
        "outputId": "a36b1792-68d8-4839-bf79-8f550c0ece63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "print(classification_report(y_test.argmax(axis=1),predictions))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        19\n",
            "           1       1.00      0.87      0.93        15\n",
            "           2       0.89      1.00      0.94        16\n",
            "\n",
            "    accuracy                           0.96        50\n",
            "   macro avg       0.96      0.96      0.96        50\n",
            "weighted avg       0.96      0.96      0.96        50\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWK0SU4BnpUp",
        "colab_type": "code",
        "outputId": "ce4e5ba5-f2ee-4cd5-d0b7-6ba921a76aee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "accuracy_score(y_test.argmax(axis=1), predictions)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.96"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1JEOgqNrLBUR",
        "colab_type": "text"
      },
      "source": [
        "## Saving and Loading Models\n",
        "\n",
        "Now that we have a model trained, let's see how we can save and load it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNrKtBvuLBUS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('myfirstmodel.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UFqrWLMFLBVA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import load_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-W6mBTXLBVM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "newmodel = load_model('myfirstmodel.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1_RcJTsLBVU",
        "colab_type": "code",
        "outputId": "5de37865-006c-4d1c-edbc-bf319a9d5a60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "newmodel.predict_classes(X_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    }
  ]
}