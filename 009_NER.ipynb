{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "009-NER.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP4QoCaqCPYCmbSRKRAFD5t",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/noircir/Python/blob/master/009_NER.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0kELfDhKTnaP",
        "colab_type": "text"
      },
      "source": [
        "# Named Entity Recognition (NER)\n",
        "spaCy has an **'ner'** pipeline component that identifies token spans fitting a predetermined set of named entities. These are available as the `ents` property of a `Doc` object."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FFQUok1gTTWB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import spacy\n",
        "nlp = spacy.load('en_core_web_sm')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Po4mZ06ppsn_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Write a function to display basic entity info:\n",
        "def show_ents(doc):\n",
        "    if doc.ents:\n",
        "        for ent in doc.ents:\n",
        "            print(ent.text+' - '+ent.label_+' - '+str(spacy.explain(ent.label_)))\n",
        "    else:\n",
        "        print('No named entities found.')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2R4YP_p5pv3Y",
        "colab_type": "code",
        "outputId": "24ec10a8-2751-4b8d-8b54-858e5d9940fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "doc = nlp(u'May I go to Washington, DC next May to see the Washington Monument?')\n",
        "\n",
        "show_ents(doc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Washington, DC - GPE - Countries, cities, states\n",
            "next May - DATE - Absolute or relative dates or periods\n",
            "the Washington Monument - ORG - Companies, agencies, institutions, etc.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_NOQ01xHp3pC",
        "colab_type": "text"
      },
      "source": [
        "## Entity annotations\n",
        "`Doc.ents` are token spans with their own set of annotations.\n",
        "<table>\n",
        "<tr><td>`ent.text`</td><td>The original entity text</td></tr>\n",
        "<tr><td>`ent.label`</td><td>The entity type's hash value</td></tr>\n",
        "<tr><td>`ent.label_`</td><td>The entity type's string description</td></tr>\n",
        "<tr><td>`ent.start`</td><td>The token span's *start* index position in the Doc</td></tr>\n",
        "<tr><td>`ent.end`</td><td>The token span's *stop* index position in the Doc</td></tr>\n",
        "<tr><td>`ent.start_char`</td><td>The entity text's *start* index position in the Doc</td></tr>\n",
        "<tr><td>`ent.end_char`</td><td>The entity text's *stop* index position in the Doc</td></tr>\n",
        "</table>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9nhQNTNpys_",
        "colab_type": "code",
        "outputId": "0c75f473-78aa-4150-9033-f73d3c8e0351",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "doc = nlp(u'Can I please borrow 500 dollars from you to buy some Microsoft stock?')\n",
        "\n",
        "for ent in doc.ents:\n",
        "    print(ent.text, ent.start, ent.end, ent.start_char, ent.end_char, ent.label_)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "500 dollars 4 6 20 31 MONEY\n",
            "Microsoft 11 12 53 62 ORG\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ulbx-3_AqLRH",
        "colab_type": "text"
      },
      "source": [
        "## NER Tags\n",
        "Tags are accessible through the `.label_` property of an entity.\n",
        "<table>\n",
        "<tr><th>TYPE</th><th>DESCRIPTION</th><th>EXAMPLE</th></tr>\n",
        "<tr><td>`PERSON`</td><td>People, including fictional.</td><td>*Fred Flintstone*</td></tr>\n",
        "<tr><td>`NORP`</td><td>Nationalities or religious or political groups.</td><td>*The Republican Party*</td></tr>\n",
        "<tr><td>`FAC`</td><td>Buildings, airports, highways, bridges, etc.</td><td>*Logan International Airport, The Golden Gate*</td></tr>\n",
        "<tr><td>`ORG`</td><td>Companies, agencies, institutions, etc.</td><td>*Microsoft, FBI, MIT*</td></tr>\n",
        "<tr><td>`GPE`</td><td>Countries, cities, states.</td><td>*France, UAR, Chicago, Idaho*</td></tr>\n",
        "<tr><td>`LOC`</td><td>Non-GPE locations, mountain ranges, bodies of water.</td><td>*Europe, Nile River, Midwest*</td></tr>\n",
        "<tr><td>`PRODUCT`</td><td>Objects, vehicles, foods, etc. (Not services.)</td><td>*Formula 1*</td></tr>\n",
        "<tr><td>`EVENT`</td><td>Named hurricanes, battles, wars, sports events, etc.</td><td>*Olympic Games*</td></tr>\n",
        "<tr><td>`WORK_OF_ART`</td><td>Titles of books, songs, etc.</td><td>*The Mona Lisa*</td></tr>\n",
        "<tr><td>`LAW`</td><td>Named documents made into laws.</td><td>*Roe v. Wade*</td></tr>\n",
        "<tr><td>`LANGUAGE`</td><td>Any named language.</td><td>*English*</td></tr>\n",
        "<tr><td>`DATE`</td><td>Absolute or relative dates or periods.</td><td>*20 July 1969*</td></tr>\n",
        "<tr><td>`TIME`</td><td>Times smaller than a day.</td><td>*Four hours*</td></tr>\n",
        "<tr><td>`PERCENT`</td><td>Percentage, including \"%\".</td><td>*Eighty percent*</td></tr>\n",
        "<tr><td>`MONEY`</td><td>Monetary values, including unit.</td><td>*Twenty Cents*</td></tr>\n",
        "<tr><td>`QUANTITY`</td><td>Measurements, as of weight or distance.</td><td>*Several kilometers, 55kg*</td></tr>\n",
        "<tr><td>`ORDINAL`</td><td>\"first\", \"second\", etc.</td><td>*9th, Ninth*</td></tr>\n",
        "<tr><td>`CARDINAL`</td><td>Numerals that do not fall under another type.</td><td>*2, Two, Fifty-two*</td></tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2iCjCQqaqTWS",
        "colab_type": "text"
      },
      "source": [
        "___\n",
        "## Adding a Named Entity to a Span\n",
        "Normally we would have spaCy build a library of named entities by training it on several samples of text.<br>In this case, we only want to add one value:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EucUtVEUqESV",
        "colab_type": "code",
        "outputId": "9ffb58f9-a742-4185-e7e5-18581ce7f791",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "doc = nlp(u'Tesla to build a U.K. factory for $6 million')\n",
        "\n",
        "show_ents(doc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "U.K. - GPE - Countries, cities, states\n",
            "$6 million - MONEY - Monetary values, including unit\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JOrqKMgcqSvg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Right now, spacy doesn't recognize Tesla. \n",
        "\n",
        "from spacy.tokens import Span\n",
        "\n",
        "# Get the hash value of the ORG entity label\n",
        "ORG = doc.vocab.strings[u'ORG']  \n",
        "\n",
        "# Create a Span for the new entity\n",
        "new_ent = Span(doc, 0, 1, label=ORG)\n",
        "\n",
        "# Add the entity to the existing Doc object\n",
        "doc.ents = list(doc.ents) + [new_ent]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YhLqetaUqqiO",
        "colab_type": "text"
      },
      "source": [
        "<font color=green>In the code above, the arguments passed to `Span()` are:</font>\n",
        "-  `doc` - the name of the Doc object\n",
        "-  `0` - the *start* index position of the span\n",
        "-  `1` - the *stop* index position (exclusive)\n",
        "-  `label=ORG` - the label assigned to our entity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVpX7l1GqmPO",
        "colab_type": "code",
        "outputId": "237cd391-21d2-4a5e-a8da-512dab5acfa8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "show_ents(doc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tesla - ORG - Companies, agencies, institutions, etc.\n",
            "U.K. - GPE - Countries, cities, states\n",
            "$6 million - MONEY - Monetary values, including unit\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CAb84NDqq3Vu",
        "colab_type": "text"
      },
      "source": [
        "___\n",
        "## Adding Named Entities to All Matching Spans\n",
        "What if we want to tag *all* occurrences of \"Tesla\"? In this section we show how to use the PhraseMatcher to identify a series of spans in the Doc:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6GefYuBqzcL",
        "colab_type": "code",
        "outputId": "732b32de-b868-45b1-af1c-84280b82cc8f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "doc = nlp(u'Our company plans to introduce a new vacuum cleaner. '\n",
        "          u'If successful, the vacuum cleaner will be our first product.')\n",
        "\n",
        "show_ents(doc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "first - ORDINAL - \"first\", \"second\", etc.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fnEihdiJq9Tl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import PhraseMatcher and create a matcher object:\n",
        "from spacy.matcher import PhraseMatcher\n",
        "matcher = PhraseMatcher(nlp.vocab)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3vkegG6prB73",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create the desired phrase patterns:\n",
        "phrase_list = ['vacuum cleaner', 'vacuum-cleaner']\n",
        "phrase_patterns = [nlp(text) for text in phrase_list]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D32fnrqyrHVu",
        "colab_type": "code",
        "outputId": "6bbe1596-e57f-4509-f5f2-3948a0f4c8dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Apply the patterns to our matcher object:\n",
        "matcher.add('newproduct', None, *phrase_patterns)\n",
        "\n",
        "# Apply the matcher to our Doc object:\n",
        "matches = matcher(doc)\n",
        "\n",
        "# See what matches occur:\n",
        "matches"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(2689272359382549672, 7, 9), (2689272359382549672, 14, 16)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EeVXUW2NrJrC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Here we create Spans from each match, and create named entities from them:\n",
        "from spacy.tokens import Span\n",
        "\n",
        "PROD = doc.vocab.strings[u'PRODUCT']\n",
        "\n",
        "new_ents = [Span(doc, match[1],match[2],label=PROD) for match in matches]\n",
        "\n",
        "doc.ents = list(doc.ents) + new_ents"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JlPknsY9rYRG",
        "colab_type": "code",
        "outputId": "cb1548eb-bfea-483e-c5cf-473bff914ad8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "show_ents(doc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "vacuum cleaner - PRODUCT - Objects, vehicles, foods, etc. (not services)\n",
            "vacuum cleaner - PRODUCT - Objects, vehicles, foods, etc. (not services)\n",
            "first - ORDINAL - \"first\", \"second\", etc.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qo4HwJEfsxCB",
        "colab_type": "text"
      },
      "source": [
        "___\n",
        "## Counting Entities\n",
        "While spaCy may not have a built-in tool for counting entities, we can pass a conditional statement into a list comprehension:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mr-AJWg8rmh_",
        "colab_type": "code",
        "outputId": "5f27663e-2ea4-45ae-9e49-3a508c1aa974",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "doc = nlp(u'Originally priced at $29.50, the sweater was marked down to five dollars.')\n",
        "\n",
        "show_ents(doc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "29.50 - MONEY - Monetary values, including unit\n",
            "five dollars - MONEY - Monetary values, including unit\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-eJJi3EP2qgT",
        "colab_type": "code",
        "outputId": "1e09f2f6-33a9-4d29-dadb-7115de3acc75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "[ent for ent in doc.ents if ent.label_=='MONEY']"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[29.50, five dollars]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ohW6a0ytXy5",
        "colab_type": "code",
        "outputId": "c97aca9e-b333-4410-c7dd-2e42fb063aee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len([ent for ent in doc.ents if ent.label_=='MONEY'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CM3tDs1btbeV",
        "colab_type": "code",
        "outputId": "3e843b02-cb12-4d87-c036-fe44a6bbf6ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# Spaces used to appear as entities, but this is fixed.\n",
        "\n",
        "text = u'''\n",
        "A U.S. regulator's preliminary investigation into the biggest oil pipeline spill this year has raised a red flag that could \n",
        "trigger an extensive and costly inspection of tens of thousands of miles of underground energy lines.\n",
        "    '''\n",
        "\n",
        "doc = nlp(text)\n",
        "\n",
        "for ent in list(doc.ents):\n",
        "    print (\"Ent Text: {} Ent_type_: {}\".format(str(ent), ent.label_))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ent Text: U.S. Ent_type_: GPE\n",
            "Ent Text: this year Ent_type_: DATE\n",
            "Ent Text: tens of thousands of miles Ent_type_: CARDINAL\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "glmA8amvtyLk",
        "colab_type": "code",
        "outputId": "3ea80177-3217-41ef-9355-96064bc1543c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "spacy.__version__"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.1.9'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lrUaVcBXuHsn",
        "colab_type": "code",
        "outputId": "14c5ea87-d6ed-499a-a50a-1a47206fd614",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "doc = nlp(u'Originally priced at $29.50,\\nthe sweater was marked down to five dollars.')\n",
        "\n",
        "show_ents(doc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "29.50 - MONEY - Monetary values, including unit\n",
            "five dollars - MONEY - Monetary values, including unit\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CFQU5fauL_6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# But, just in case, a simple fix that can be added to the nlp pipeline:\n",
        "# a quick function to remove ents formed on whitespace:\n",
        "\n",
        "def remove_whitespace_entities(doc):\n",
        "    doc.ents = [e for e in doc.ents if not e.text.isspace()]\n",
        "    return doc\n",
        "\n",
        "# Insert this into the pipeline AFTER the ner component:\n",
        "nlp.add_pipe(remove_whitespace_entities, after='ner')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Z4pxzYBufpT",
        "colab_type": "code",
        "outputId": "f4f975a6-23a4-4317-f859-35b22e9fd961",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Rerun nlp on the text above, and show ents:\n",
        "doc = nlp(u'Originally priced at $29.50,\\nthe sweater was marked down to five dollars.')\n",
        "\n",
        "show_ents(doc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "29.50 - MONEY - Monetary values, including unit\n",
            "five dollars - MONEY - Monetary values, including unit\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wigh2f-KuxpG",
        "colab_type": "text"
      },
      "source": [
        "For more on **Named Entity Recognition** visit https://spacy.io/usage/linguistic-features#101"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fM2P3bWuu6Vt",
        "colab_type": "text"
      },
      "source": [
        "___\n",
        "## Noun Chunks\n",
        "`Doc.noun_chunks` are *base noun phrases*: token spans that include the noun and words describing the noun. Noun chunks cannot be nested, cannot overlap, and do not involve prepositional phrases or relative clauses.<br>\n",
        "Where `Doc.ents` rely on the **ner** pipeline component, `Doc.noun_chunks` are provided by the **parser**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nWkuVYoau2yI",
        "colab_type": "text"
      },
      "source": [
        "### `noun_chunks` components:\n",
        "<table>\n",
        "<tr><td>`.text`</td><td>The original noun chunk text.</td></tr>\n",
        "<tr><td>`.root.text`</td><td>The original text of the word connecting the noun chunk to the rest of the parse.</td></tr>\n",
        "<tr><td>`.root.dep_`</td><td>Dependency relation connecting the root to its head.</td></tr>\n",
        "<tr><td>`.root.head.text`</td><td>The text of the root token's head.</td></tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIBYUXM7utRE",
        "colab_type": "code",
        "outputId": "a0bc581b-eebe-43ae-fc27-9fbfa4c0bd62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "doc = nlp(u\"Autonomous cars shift insurance liability toward manufacturers.\")\n",
        "\n",
        "for chunk in doc.noun_chunks:\n",
        "    print(chunk.text+' - '+chunk.root.text+' - '+chunk.root.dep_+' - '+chunk.root.head.text)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Autonomous cars - cars - nsubj - shift\n",
            "insurance liability - liability - dobj - shift\n",
            "manufacturers - manufacturers - pobj - toward\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0tSWQCnUvAa7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}